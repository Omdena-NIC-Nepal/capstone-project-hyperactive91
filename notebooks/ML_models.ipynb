{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77ca492-dde1-4026-b6bc-4845b5a95f3b",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc458886-7d52-47ea-8d9f-4bf2000e9389",
   "metadata": {},
   "source": [
    "### Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f52b8ed-8196-4b74-a79c-7f576cbb38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load preprocessed feature datasets\n",
    "climate_yearly = pd.read_csv(\"../data/preprocessed/climate_yearly.csv\")\n",
    "merged_with_coords = pd.read_csv(\"../data/preprocessed/merged_with_coords.csv\")\n",
    "merged_scaled = pd.read_csv(\"../data/preprocessed/merged_scaled.csv\")\n",
    "glacier_features = pd.read_csv(\"../data/preprocessed/glacier_features.csv\")\n",
    "glacier_long = pd.read_csv(\"../data/preprocessed/glacier_long.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0995c28-cfb9-4b3d-8df3-0b3dfe5429ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.6.1\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: https://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: BSD 3-Clause License\n",
      "\n",
      " Copyright (c) 2007-2024 The scikit-learn developers.\n",
      " All rights reserved.\n",
      "\n",
      " Redistribution and use in source and binary forms, with or without\n",
      " modification, are permitted provided that the following conditions are met:\n",
      "\n",
      " * Redistributions of source code must retain the above copyright notice, this\n",
      "   list of conditions and the following disclaimer.\n",
      "\n",
      " * Redistributions in binary form must reproduce the above copyright notice,\n",
      "   this list of conditions and the following disclaimer in the documentation\n",
      "   and/or other materials provided with the distribution.\n",
      "\n",
      " * Neither the name of the copyright holder nor the names of its\n",
      "   contributors may be used to endorse or promote products derived from\n",
      "   this software without specific prior written permission.\n",
      "\n",
      " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      " DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      " FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      " DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      " SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      " OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      " OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "\n",
      " ----\n",
      "\n",
      " This binary distribution of scikit-learn also bundles the following software:\n",
      "\n",
      " ----\n",
      "\n",
      " Name: Microsoft Visual C++ Runtime Files\n",
      " Files: sklearn\\.libs\\*.dll\n",
      " Availability: https://learn.microsoft.com/en-us/visualstudio/releases/2015/2015-redistribution-vs\n",
      "\n",
      " Subject to the License Terms for the software, you may copy and distribute with your\n",
      " program any of the files within the followng folder and its subfolders except as noted\n",
      " below. You may not modify these files.\n",
      "\n",
      " C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\redist\n",
      "\n",
      " You may not distribute the contents of the following folders:\n",
      "\n",
      " C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\redist\\debug_nonredist\n",
      " C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\redist\\onecore\\debug_nonredist\n",
      "\n",
      " Subject to the License Terms for the software, you may copy and distribute the following\n",
      " files with your program in your program‚Äôs application local folder or by deploying them\n",
      " into the Global Assembly Cache (GAC):\n",
      "\n",
      " VC\\atlmfc\\lib\\mfcmifc80.dll\n",
      " VC\\atlmfc\\lib\\amd64\\mfcmifc80.dll\n",
      "\n",
      "Location: C:\\Users\\Wlink\\anaconda3\\Lib\\site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: imbalanced-learn\n"
     ]
    }
   ],
   "source": [
    "!pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65896290-cf5c-4978-a741-a53b447a4306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/Wlink/anaconda3/Lib/site-packages\")\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352bd510-8ce0-4722-a2e8-b37cad854756",
   "metadata": {},
   "source": [
    "### ‚úÖ Climate Zone Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd781d32-00ed-4429-992f-b40e1deb2366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Random Forest Evaluation:\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Alpine       1.00      1.00      1.00        37\n",
      " Subtropical       1.00      1.00      1.00       201\n",
      "   Temperate       1.00      1.00      1.00        88\n",
      "    Tropical       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           1.00       335\n",
      "   macro avg       0.97      1.00      0.99       335\n",
      "weighted avg       1.00      1.00      1.00       335\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[ 37   0   0   0]\n",
      " [  0 200   0   1]\n",
      " [  0   0  88   0]\n",
      " [  0   0   0   9]]\n",
      "üíæ Saved to: ../data/preprocessed/climate_zone_random_forest.joblib\n",
      "üìå Top Feature Importances:\n",
      "  avg_temp                       ‚Üí 0.5167\n",
      "  avg_max_temp                   ‚Üí 0.3502\n",
      "  temp_range_stddev              ‚Üí 0.0542\n",
      "  highheat_days                  ‚Üí 0.0428\n",
      "  annual_precip                  ‚Üí 0.0239\n",
      "  avg_humidity                   ‚Üí 0.0122\n",
      "\n",
      "üîç Gradient Boosting Evaluation:\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Alpine       1.00      1.00      1.00        37\n",
      " Subtropical       1.00      1.00      1.00       201\n",
      "   Temperate       1.00      1.00      1.00        88\n",
      "    Tropical       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           1.00       335\n",
      "   macro avg       0.97      1.00      0.99       335\n",
      "weighted avg       1.00      1.00      1.00       335\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[ 37   0   0   0]\n",
      " [  0 200   0   1]\n",
      " [  0   0  88   0]\n",
      " [  0   0   0   9]]\n",
      "üíæ Saved to: ../data/preprocessed/climate_zone_gradient_boosting.joblib\n",
      "üìå Top Feature Importances:\n",
      "  avg_temp                       ‚Üí 0.8179\n",
      "  avg_max_temp                   ‚Üí 0.1821\n",
      "  highheat_days                  ‚Üí 0.0000\n",
      "  avg_humidity                   ‚Üí 0.0000\n",
      "  temp_range_stddev              ‚Üí -0.0000\n",
      "  annual_precip                  ‚Üí -0.0000\n",
      "\n",
      "üîç SVM (RBF) Evaluation:\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Alpine       0.90      0.24      0.38        37\n",
      " Subtropical       0.66      0.99      0.79       201\n",
      "   Temperate       0.42      0.11      0.18        88\n",
      "    Tropical       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.65       335\n",
      "   macro avg       0.49      0.34      0.34       335\n",
      "weighted avg       0.61      0.65      0.56       335\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[  9  16  12   0]\n",
      " [  0 199   2   0]\n",
      " [  1  77  10   0]\n",
      " [  0   9   0   0]]\n",
      "üíæ Saved to: ../data/preprocessed/climate_zone_svm_rbf.joblib\n",
      "‚ö†Ô∏è Feature importances not available.\n",
      "\n",
      "üìã Model Summary:\n",
      "               Model  Test Accuracy  CV Accuracy    CV Std\n",
      "0      Random Forest       0.997015     0.999403  0.001194\n",
      "1  Gradient Boosting       0.997015     0.999403  0.001194\n",
      "2          SVM (RBF)       0.650746     0.653517  0.015394\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- Step 0: Load data and ensure output directory ---\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "try:\n",
    "    merged_with_coords\n",
    "except NameError:\n",
    "    merged_with_coords = pd.read_csv(\"../data/preprocessed/merged_with_coords.csv\")\n",
    "    print(\"‚úÖ Loaded merged_with_coords.\")\n",
    "\n",
    "# --- Step 1: Assign climate zones if not present ---\n",
    "def assign_climate_zone(row):\n",
    "    if row['avg_temp'] >= 25:\n",
    "        return 'Tropical'\n",
    "    elif row['avg_temp'] >= 15:\n",
    "        return 'Subtropical'\n",
    "    elif row['avg_temp'] >= 5:\n",
    "        return 'Temperate'\n",
    "    else:\n",
    "        return 'Alpine'\n",
    "\n",
    "if 'climate_zone' not in merged_with_coords.columns:\n",
    "    merged_with_coords['climate_zone'] = merged_with_coords.apply(assign_climate_zone, axis=1)\n",
    "\n",
    "# --- Step 2: Define features and target ---\n",
    "features = [\n",
    "    'avg_temp', 'avg_max_temp', 'annual_precip',\n",
    "    'avg_humidity', 'temp_range_stddev', 'highheat_days'\n",
    "]\n",
    "target = 'climate_zone'\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = merged_with_coords.dropna(subset=features + [target]).copy()\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# --- Step 3: Split data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Step 4: Define models ---\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# --- Step 5: Train, Evaluate, Save ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç {name} Evaluation:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"‚úÖ Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    print(\"üìâ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': model.score(X_test, y_test),\n",
    "        'CV Accuracy': np.mean(cv),\n",
    "        'CV Std': np.std(cv)\n",
    "    })\n",
    "\n",
    "    # Save trained model\n",
    "    model_key = name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    filename = f\"../data/preprocessed/climate_zone_{model_key}.joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"üíæ Saved to: {filename}\")\n",
    "\n",
    "    # Show feature importances if available\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"üìå Top Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        for feat, score in importances.items():\n",
    "            print(f\"  {feat:<30} ‚Üí {score:.4f}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Feature importances not available.\")\n",
    "\n",
    "# --- Step 6: Summary ---\n",
    "print(\"\\nüìã Model Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d039d3-837d-4531-afe7-64f0a42c9d49",
   "metadata": {},
   "source": [
    "### ‚úÖ Extreme Heat Classification based on district-year climate conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "243e2864-e0fe-4ae5-a454-145dfd302681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç RANDOM_FOREST Evaluation\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       527\n",
      "           1       0.92      0.73      0.81        62\n",
      "\n",
      "    accuracy                           0.96       589\n",
      "   macro avg       0.94      0.86      0.90       589\n",
      "weighted avg       0.96      0.96      0.96       589\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[523   4]\n",
      " [ 17  45]]\n",
      "üìå Feature Importances:\n",
      "avg_max_temp              0.277068\n",
      "avg_temp                  0.161855\n",
      "highheat_days_lag1        0.142808\n",
      "avg_temp_lag1             0.101432\n",
      "temp_range_stddev         0.076850\n",
      "avg_wind                  0.040485\n",
      "temp_range_stddev_lag1    0.039728\n",
      "avg_humidity              0.039708\n",
      "annual_precip             0.033616\n",
      "precip_zscore             0.031232\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/heatwave_model_random_forest.joblib\n",
      "\n",
      "üîç GRADIENT_BOOSTING Evaluation\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       527\n",
      "           1       0.85      0.76      0.80        62\n",
      "\n",
      "    accuracy                           0.96       589\n",
      "   macro avg       0.91      0.87      0.89       589\n",
      "weighted avg       0.96      0.96      0.96       589\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[519   8]\n",
      " [ 15  47]]\n",
      "üìå Feature Importances:\n",
      "avg_max_temp              0.677379\n",
      "highheat_days_lag1        0.079987\n",
      "temp_range_stddev         0.062567\n",
      "annual_precip             0.039872\n",
      "avg_temp                  0.030724\n",
      "avg_wind                  0.025214\n",
      "avg_temp_lag1             0.024698\n",
      "avg_humidity              0.023164\n",
      "temp_range_stddev_lag1    0.011759\n",
      "annual_precip_lag1        0.008437\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/heatwave_model_gradient_boosting.joblib\n",
      "\n",
      "üîç SVM_RBF Evaluation\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       527\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.89       589\n",
      "   macro avg       0.45      0.50      0.47       589\n",
      "weighted avg       0.80      0.89      0.85       589\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[527   0]\n",
      " [ 62   0]]\n",
      "‚ö†Ô∏è Feature importances not available for this model.\n",
      "üíæ Model saved to: ../data/preprocessed/heatwave_model_svm_rbf.joblib\n",
      "\n",
      "üìã Model Performance Summary:\n",
      "               Model  Test Accuracy  CV Accuracy    CV Std\n",
      "0      random_forest       0.964346     0.955441  0.023962\n",
      "1  gradient_boosting       0.960951     0.954596  0.026504\n",
      "2            svm_rbf       0.894737     0.895162  0.000988\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Define binary heatwave label\n",
    "threshold = 30\n",
    "climate_yearly['highheat_year'] = (climate_yearly['highheat_days'] >= threshold).astype(int)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = climate_yearly.drop(columns=[\n",
    "    'District', 'YEAR', 'highheat_days', 'highheat_year'\n",
    "])\n",
    "X = X.select_dtypes(include=[np.number]).dropna()\n",
    "y = climate_yearly.loc[X.index, 'highheat_year']\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'svm_rbf': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "summary = []\n",
    "\n",
    "# Train, Evaluate, Save\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç {name.upper()} Evaluation\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"‚úÖ Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"üìâ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': model.score(X_test, y_test),\n",
    "        'CV Accuracy': np.mean(cv),\n",
    "        'CV Std': np.std(cv)\n",
    "    })\n",
    "\n",
    "    # Feature importances (for tree-based models)\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        print(\"üìå Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(importances.head(10))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Feature importances not available for this model.\")\n",
    "\n",
    "    # Save model\n",
    "    path = f\"../data/preprocessed/heatwave_model_{name}.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"üíæ Model saved to: {path}\")\n",
    "\n",
    "# === Step 8: Summary ===\n",
    "print(\"\\nüìã Model Performance Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a94264-5953-44e3-9409-b32656bb555a",
   "metadata": {},
   "source": [
    "### ‚úÖ Drought Risk Category Classification using existing SPI proxy (precip_zscore) in climate_yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f051617f-9256-42d6-a78f-d68e69a5666a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç RANDOM_FOREST Evaluation\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Mild       1.00      1.00      1.00       107\n",
      "    Moderate       1.00      1.00      1.00       110\n",
      "        None       1.00      1.00      1.00       357\n",
      "      Severe       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00       589\n",
      "   macro avg       1.00      1.00      1.00       589\n",
      "weighted avg       1.00      1.00      1.00       589\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[107   0   0   0]\n",
      " [  0 110   0   0]\n",
      " [  0   0 357   0]\n",
      " [  0   0   0  15]]\n",
      "üìå Feature Importances:\n",
      "precip_zscore         0.526629\n",
      "annual_precip         0.146229\n",
      "precip_zscore_lag1    0.099228\n",
      "avg_humidity          0.070069\n",
      "annual_precip_lag1    0.040478\n",
      "temp_range_stddev     0.025521\n",
      "avg_wind              0.023295\n",
      "avg_max_temp          0.020182\n",
      "avg_temp_lag1         0.019290\n",
      "avg_temp              0.014792\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/drought_model_random_forest.joblib\n",
      "\n",
      "üîç GRADIENT_BOOSTING Evaluation\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Mild       1.00      1.00      1.00       107\n",
      "    Moderate       1.00      1.00      1.00       110\n",
      "        None       1.00      1.00      1.00       357\n",
      "      Severe       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00       589\n",
      "   macro avg       1.00      1.00      1.00       589\n",
      "weighted avg       1.00      1.00      1.00       589\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[107   0   0   0]\n",
      " [  0 110   0   0]\n",
      " [  0   0 357   0]\n",
      " [  0   0   0  15]]\n",
      "üìå Feature Importances:\n",
      "precip_zscore             1.000000e+00\n",
      "temp_range_stddev_lag1    1.458950e-15\n",
      "precip_zscore_lag1        1.049373e-15\n",
      "avg_max_temp              8.347656e-16\n",
      "avg_temp_lag1             6.526929e-16\n",
      "avg_temp                  4.085518e-16\n",
      "avg_humidity              1.227044e-16\n",
      "highheat_days_lag1        4.014548e-17\n",
      "temp_range_stddev         2.304032e-17\n",
      "annual_precip_lag1        6.466733e-18\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/drought_model_gradient_boosting.joblib\n",
      "\n",
      "üîç SVM_RBF Evaluation\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Mild       0.48      0.38      0.43       107\n",
      "    Moderate       0.56      0.72      0.63       110\n",
      "        None       0.89      0.90      0.90       357\n",
      "      Severe       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.75       589\n",
      "   macro avg       0.48      0.50      0.49       589\n",
      "weighted avg       0.73      0.75      0.74       589\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[ 41  32  34   0]\n",
      " [ 24  79   7   0]\n",
      " [ 19  15 323   0]\n",
      " [  1  14   0   0]]\n",
      "‚ö†Ô∏è Feature importances not available for this model.\n",
      "üíæ Model saved to: ../data/preprocessed/drought_model_svm_rbf.joblib\n",
      "\n",
      "üìã Model Performance Summary:\n",
      "               Model  Test Accuracy  CV Accuracy    CV Std\n",
      "0      random_forest       1.000000     0.998301  0.001589\n",
      "1  gradient_boosting       1.000000     1.000000  0.000000\n",
      "2            svm_rbf       0.752122     0.734712  0.040177\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# --- Step 1: Ensure output directory exists ---\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "# --- Step 2: Classify drought risk based on SPI-like z-score ---\n",
    "def classify_spi(z):\n",
    "    if z >= -0.5:\n",
    "        return \"None\"\n",
    "    elif z >= -1.0:\n",
    "        return \"Mild\"\n",
    "    elif z >= -1.5:\n",
    "        return \"Moderate\"\n",
    "    elif z >= -2.0:\n",
    "        return \"Severe\"\n",
    "    else:\n",
    "        return \"Extreme\"\n",
    "\n",
    "climate_yearly['drought_risk'] = climate_yearly['precip_zscore'].apply(classify_spi)\n",
    "\n",
    "# --- Step 3: Define features and target ---\n",
    "X = climate_yearly.drop(columns=[\n",
    "    'highheat_days', 'highheat_year', 'drought_risk',\n",
    "    'District', 'YEAR'\n",
    "])\n",
    "X = X.select_dtypes(include=[np.number]).dropna()\n",
    "y = climate_yearly.loc[X.index, 'drought_risk']\n",
    "\n",
    "# --- Step 4: Encode target labels ---\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# --- Step 5: Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.25, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "# --- Step 6: Define classifiers ---\n",
    "models = {\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'svm_rbf': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# --- Step 7: Train, evaluate, and save ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç {name.upper()} Evaluation\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"‚úÖ Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))\n",
    "\n",
    "    print(\"üìâ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y_encoded, cv=5, scoring='accuracy')\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': model.score(X_test, y_test),\n",
    "        'CV Accuracy': np.mean(cv_scores),\n",
    "        'CV Std': np.std(cv_scores)\n",
    "    })\n",
    "\n",
    "    # Feature importances\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"üìå Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(importances.head(10))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Feature importances not available for this model.\")\n",
    "\n",
    "    # Save model\n",
    "    path = f\"../data/preprocessed/drought_model_{name}.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"üíæ Model saved to: {path}\")\n",
    "\n",
    "# --- Step 8: Print Summary ---\n",
    "print(\"\\nüìã Model Performance Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a643a-dee5-41fd-832f-106009877ae4",
   "metadata": {},
   "source": [
    "### ‚úÖ Cereal Yield Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee4af223-a63d-4ab9-9065-5f69a9eb9823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç RANDOM_FOREST Evaluation:\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00        48\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[ 6  0]\n",
      " [ 0 48]]\n",
      "üíæ Model saved to: ../data/preprocessed/yield_model_random_forest.joblib\n",
      "üìå Top Feature Importances:\n",
      "total_yield_minmax    0.156975\n",
      "total_yield_zscore    0.106118\n",
      "pd_minmax             0.081320\n",
      "pd_zscore             0.069197\n",
      "mz                    0.051258\n",
      "pd                    0.049521\n",
      "mz_minmax             0.047322\n",
      "pd_ma3                0.047286\n",
      "pd_ma3_zscore         0.036526\n",
      "pd_ma3_minmax         0.029252\n",
      "dtype: float64\n",
      "\n",
      "üîç GRADIENT_BOOSTING Evaluation:\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00        48\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[ 6  0]\n",
      " [ 0 48]]\n",
      "üíæ Model saved to: ../data/preprocessed/yield_model_gradient_boosting.joblib\n",
      "üìå Top Feature Importances:\n",
      "total_yield_zscore    0.610047\n",
      "total_yield_minmax    0.389953\n",
      "bl                    0.000000\n",
      "mz                    0.000000\n",
      "pd                    0.000000\n",
      "bw                    0.000000\n",
      "ml                    0.000000\n",
      "pd_change             0.000000\n",
      "wt_change             0.000000\n",
      "mz_ma3                0.000000\n",
      "dtype: float64\n",
      "\n",
      "üîç SVM_RBF Evaluation:\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.96      1.00      0.98        48\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.98      0.83      0.89        54\n",
      "weighted avg       0.96      0.96      0.96        54\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[ 4  2]\n",
      " [ 0 48]]\n",
      "üíæ Model saved to: ../data/preprocessed/yield_model_svm_rbf.joblib\n",
      "‚ö†Ô∏è Feature importances not available for this model.\n",
      "\n",
      "üìã Model Summary:\n",
      "               Model  Test Accuracy  CV Accuracy    CV Std\n",
      "0      random_forest       1.000000     0.986152  0.011308\n",
      "1  gradient_boosting       1.000000     0.990803  0.011265\n",
      "2            svm_rbf       0.962963     0.958457  0.026800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Ensure output directory exists \n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "# Create Binary Yield Label\n",
    "threshold = merged_scaled['total_yield'].median()\n",
    "merged_scaled['yield_class'] = (merged_scaled['total_yield'] > threshold).astype(int)\n",
    "\n",
    "# Define Features and Labels\n",
    "X_raw = merged_scaled.drop(columns=[\n",
    "    'total_yield', 'yield_class', 'district_name', 'year',\n",
    "    'CENTROID_LAT', 'CENTROID_LON'\n",
    "])\n",
    "\n",
    "X = pd.get_dummies(X_raw, drop_first=True)\n",
    "y = merged_scaled['yield_class']\n",
    "\n",
    "# Drop rows with missing values\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Define and Train Models\n",
    "models = {\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'svm_rbf': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# Train, Evaluate, Save\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç {name.upper()} Evaluation:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"‚úÖ Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    print(\"üìâ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': model.score(X_test, y_test),\n",
    "        'CV Accuracy': np.mean(cv_scores),\n",
    "        'CV Std': np.std(cv_scores)\n",
    "    })\n",
    "\n",
    "    # Save model\n",
    "    model_path = f\"../data/preprocessed/yield_model_{name}.joblib\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"üíæ Model saved to: {model_path}\")\n",
    "\n",
    "    # Feature importance\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"üìå Top Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(importances.head(10))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Feature importances not available for this model.\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nüìã Model Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1b938-20c7-4ec3-a87e-69c1601a195b",
   "metadata": {},
   "source": [
    "#### ‚úÖ Glacier Retreat Severity Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8db73b3-da7b-48cc-abe8-2a385f7c8680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç RANDOM_FOREST Evaluation:\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      0.50      0.67         2\n",
      "    Moderate       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.88      0.75      0.76         5\n",
      "weighted avg       0.85      0.80      0.78         5\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[1 1]\n",
      " [0 3]]\n",
      "üìä 5-Fold CV Accuracy: 0.900 ¬± 0.200\n",
      "üìå Feature Importances:\n",
      "  area_loss_pct             ‚Üí 0.2681\n",
      "  volume_loss_pct           ‚Üí 0.1742\n",
      "  ice_volume_2010           ‚Üí 0.1469\n",
      "  ice_volume_1980           ‚Üí 0.0842\n",
      "  glacier_area_2010         ‚Üí 0.0779\n",
      "  glacier_area_1980         ‚Üí 0.0748\n",
      "  volume_loss_km3           ‚Üí 0.0693\n",
      "  min_elev_1980             ‚Üí 0.0427\n",
      "  min_elev_2010             ‚Üí 0.0323\n",
      "  area_loss_km2             ‚Üí 0.0252\n",
      "  elev_rise_m               ‚Üí 0.0044\n",
      "üíæ Model saved to: ../data/preprocessed/glacier_model_random_forest.joblib\n",
      "\n",
      "üîç SVM_RBF Evaluation:\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.00      0.00      0.00         2\n",
      "    Moderate       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.30      0.50      0.38         5\n",
      "weighted avg       0.36      0.60      0.45         5\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[0 2]\n",
      " [0 3]]\n",
      "üìä 5-Fold CV Accuracy: 0.683 ¬± 0.097\n",
      "‚ö†Ô∏è Feature importance not available for this model.\n",
      "üíæ Model saved to: ../data/preprocessed/glacier_model_svm_rbf.joblib\n",
      "\n",
      "üîç GRADIENT_BOOSTING Evaluation:\n",
      "‚úÖ Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      1.00      1.00         2\n",
      "    Moderate       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         5\n",
      "   macro avg       1.00      1.00      1.00         5\n",
      "weighted avg       1.00      1.00      1.00         5\n",
      "\n",
      "üìâ Confusion Matrix:\n",
      "[[2 0]\n",
      " [0 3]]\n",
      "üìä 5-Fold CV Accuracy: 0.850 ¬± 0.200\n",
      "üìå Feature Importances:\n",
      "  area_loss_pct             ‚Üí 1.0000\n",
      "  glacier_area_2010         ‚Üí 0.0000\n",
      "  glacier_area_1980         ‚Üí 0.0000\n",
      "  ice_volume_1980           ‚Üí 0.0000\n",
      "  ice_volume_2010           ‚Üí 0.0000\n",
      "  min_elev_2010             ‚Üí 0.0000\n",
      "  min_elev_1980             ‚Üí 0.0000\n",
      "  area_loss_km2             ‚Üí 0.0000\n",
      "  volume_loss_km3           ‚Üí 0.0000\n",
      "  volume_loss_pct           ‚Üí 0.0000\n",
      "  elev_rise_m               ‚Üí 0.0000\n",
      "üíæ Model saved to: ../data/preprocessed/glacier_model_gradient_boosting.joblib\n",
      "\n",
      "üìã Summary Comparison:\n",
      "               Model  Test Accuracy  CV Accuracy Mean  CV Accuracy Std\n",
      "0      random_forest            0.8          0.900000         0.200000\n",
      "1            svm_rbf            0.6          0.683333         0.097183\n",
      "2  gradient_boosting            1.0          0.850000         0.200000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- Step 0: Ensure output directory exists ---\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "\n",
    "X = glacier_features[[\n",
    "    'glacier_area_1980', 'glacier_area_2010',\n",
    "    'ice_volume_1980', 'ice_volume_2010',\n",
    "    'min_elev_1980', 'min_elev_2010',\n",
    "    'area_loss_km2', 'area_loss_pct',\n",
    "    'volume_loss_km3', 'volume_loss_pct',\n",
    "    'elev_rise_m'\n",
    "]]\n",
    "y = glacier_features['retreat_severity']\n",
    "\n",
    "# --- Step 2: Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Step 3: Models ---\n",
    "models = {\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'svm_rbf': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# --- Step 4: Train, evaluate, and save models ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç {name.upper()} Evaluation:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Report\n",
    "    print(\"‚úÖ Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    print(\"üìâ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # CV Score\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    cv_mean, cv_std = scores.mean(), scores.std()\n",
    "    print(f\"üìä 5-Fold CV Accuracy: {cv_mean:.3f} ¬± {cv_std:.3f}\")\n",
    "\n",
    "    # Feature importances\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        print(\"üìå Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        for feat, val in importances.items():\n",
    "            print(f\"  {feat:<25} ‚Üí {val:.4f}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Feature importance not available for this model.\")\n",
    "\n",
    "    # Save model\n",
    "    model_path = f\"../data/preprocessed/glacier_model_{name}.joblib\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"üíæ Model saved to: {model_path}\")\n",
    "\n",
    "    # Add to summary\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': model.score(X_test, y_test),\n",
    "        'CV Accuracy Mean': cv_mean,\n",
    "        'CV Accuracy Std': cv_std\n",
    "    })\n",
    "\n",
    "# --- Step 5: Summary Table ---\n",
    "print(\"\\nüìã Summary Comparison:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0367a-440f-40a2-9dc6-a67cdc006526",
   "metadata": {},
   "source": [
    "### üîπ Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bef07a-ee7e-407c-8fe4-6cafeee5bb39",
   "metadata": {},
   "source": [
    "### ‚úÖ Cereal Yield Prediction (Regression Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "767314fc-3578-445a-9477-21e83650cac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Linear Regression Evaluation:\n",
      "üìà RMSE: 0.00\n",
      "üìâ MAE : 0.00\n",
      "üîÅ R¬≤  : 1.0000\n",
      "üíæ Model saved to: ../data/preprocessed/yield_regressor_linear_regression.joblib\n",
      "üìå Top Coefficients:\n",
      "mz                    0.666665\n",
      "pd                    0.666665\n",
      "wt                    0.666665\n",
      "pd_lag1               0.333333\n",
      "mz_change             0.333333\n",
      "mz_lag1               0.333332\n",
      "wt_change             0.333332\n",
      "wt_lag1               0.333332\n",
      "pd_change             0.333332\n",
      "total_yield_zscore    0.001069\n",
      "dtype: float64\n",
      "\n",
      "üîç Ridge Regression Evaluation:\n",
      "üìà RMSE: 0.00\n",
      "üìâ MAE : 0.00\n",
      "üîÅ R¬≤  : 1.0000\n",
      "üíæ Model saved to: ../data/preprocessed/yield_regressor_ridge_regression.joblib\n",
      "üìå Top Coefficients:\n",
      "mz                    0.666665\n",
      "pd                    0.666665\n",
      "wt                    0.666665\n",
      "pd_lag1               0.333333\n",
      "mz_change             0.333333\n",
      "mz_lag1               0.333332\n",
      "wt_change             0.333332\n",
      "wt_lag1               0.333332\n",
      "pd_change             0.333332\n",
      "total_yield_zscore    0.001069\n",
      "dtype: float64\n",
      "\n",
      "üîç Lasso Regression Evaluation:\n",
      "üìà RMSE: 0.67\n",
      "üìâ MAE : 0.52\n",
      "üîÅ R¬≤  : 1.0000\n",
      "üíæ Model saved to: ../data/preprocessed/yield_regressor_lasso_regression.joblib\n",
      "üìå Top Coefficients:\n",
      "bl_zscore           358.582565\n",
      "bw_zscore           326.802877\n",
      "mz_ma3_zscore       147.694931\n",
      "mz_zscore          -133.910733\n",
      "wt_zscore           113.906443\n",
      "mz_lag1_zscore      -81.840284\n",
      "pd_zscore            62.757294\n",
      "ml_zscore           -45.836502\n",
      "mz_change_zscore    -32.327958\n",
      "wt_change_zscore     30.766079\n",
      "dtype: float64\n",
      "\n",
      "üîç Random Forest Evaluation:\n",
      "üìà RMSE: 129.39\n",
      "üìâ MAE : 74.05\n",
      "üîÅ R¬≤  : 0.9957\n",
      "üíæ Model saved to: ../data/preprocessed/yield_regressor_random_forest.joblib\n",
      "üìå Top Feature Importances:\n",
      "total_yield_zscore    0.467576\n",
      "total_yield_minmax    0.460087\n",
      "pd                    0.016834\n",
      "pd_zscore             0.007980\n",
      "pd_minmax             0.007171\n",
      "pd_ma3                0.003031\n",
      "pd_ma3_zscore         0.002445\n",
      "mz_zscore             0.002130\n",
      "wt                    0.001799\n",
      "pd_ma3_minmax         0.001621\n",
      "dtype: float64\n",
      "\n",
      "üîç Gradient Boosting Evaluation:\n",
      "üìà RMSE: 72.73\n",
      "üìâ MAE : 41.00\n",
      "üîÅ R¬≤  : 0.9987\n",
      "üíæ Model saved to: ../data/preprocessed/yield_regressor_gradient_boosting.joblib\n",
      "üìå Top Feature Importances:\n",
      "total_yield_zscore    0.590704\n",
      "total_yield_minmax    0.402175\n",
      "mz_zscore             0.001773\n",
      "bl_zscore             0.001600\n",
      "ml                    0.000827\n",
      "bl                    0.000809\n",
      "bl_minmax             0.000775\n",
      "mz_ma3_zscore         0.000419\n",
      "mz                    0.000338\n",
      "wt_ma3_zscore         0.000300\n",
      "dtype: float64\n",
      "\n",
      "üìã Regression Model Summary:\n",
      "               Model          RMSE           MAE  R¬≤ Score  CV R¬≤ Mean  \\\n",
      "0  linear_regression  4.107204e-12  3.056913e-12  1.000000    1.000000   \n",
      "1   ridge_regression  2.677706e-05  2.103500e-05  1.000000    1.000000   \n",
      "2   lasso_regression  6.727233e-01  5.205736e-01  1.000000    1.000000   \n",
      "3      random_forest  1.293949e+02  7.404778e+01  0.995748    0.971478   \n",
      "4  gradient_boosting  7.273157e+01  4.100111e+01  0.998657    0.991604   \n",
      "\n",
      "      CV R¬≤ Std  \n",
      "0  0.000000e+00  \n",
      "1  1.110223e-16  \n",
      "2  1.347981e-07  \n",
      "3  2.859690e-02  \n",
      "4  5.181846e-03  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# --- Step 0: Ensure output directory exists ---\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "y = merged_scaled['total_yield']\n",
    "X_raw = merged_scaled.drop(columns=[\n",
    "    'total_yield', 'yield_class', 'district_name', 'year',\n",
    "    'CENTROID_LAT', 'CENTROID_LON'\n",
    "])\n",
    "X = pd.get_dummies(X_raw, drop_first=True)\n",
    "\n",
    "# --- Step 2: Drop missing values ---\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# --- Step 3: Train-test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# --- Step 4: Define regression models ---\n",
    "models = {\n",
    "    'linear_regression': LinearRegression(),\n",
    "    'ridge_regression': Ridge(alpha=1.0),\n",
    "    'lasso_regression': Lasso(alpha=0.1),\n",
    "    'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# --- Step 5: Train, Evaluate, Save ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç {name.replace('_', ' ').title()} Evaluation:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"üìà RMSE: {rmse:.2f}\")\n",
    "    print(f\"üìâ MAE : {mae:.2f}\")\n",
    "    print(f\"üîÅ R¬≤  : {r2:.4f}\")\n",
    "\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R¬≤ Score': r2,\n",
    "        'CV R¬≤ Mean': np.mean(cv_scores),\n",
    "        'CV R¬≤ Std': np.std(cv_scores)\n",
    "    })\n",
    "\n",
    "    # Save model to disk\n",
    "    model_path = f\"../data/preprocessed/yield_regressor_{name}.joblib\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"üíæ Model saved to: {model_path}\")\n",
    "\n",
    "    # Display feature importance or coefficients\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"üìå Top Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(importances.head(10))\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print(\"üìå Top Coefficients:\")\n",
    "        coefs = pd.Series(model.coef_, index=X.columns).sort_values(key=np.abs, ascending=False)\n",
    "        print(coefs.head(10))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Feature importance not available.\")\n",
    "\n",
    "# --- Step 6: Print summary ---\n",
    "print(\"\\nüìã Regression Model Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8732091-1fdf-4e54-bc66-2b5b84e9d86e",
   "metadata": {},
   "source": [
    "### ‚úÖ Glacier Area and Volume Loss Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "718b4810-b0a0-4c8e-ae68-8536ef560746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåê Predicting Glacier Area Loss:\n",
      "\n",
      "üîç LINEAR_REGRESSION (area) Regression:\n",
      "üìà RMSE: 0.00 | üìâ MAE: 0.00 | üîÅ R¬≤: 1.0000\n",
      "üìä CV R¬≤: 1.0000 ¬± 0.0000\n",
      "üìå Top Coefficients:\n",
      "glacier_area_1980          -1.000000e+00\n",
      "glacier_area_2010           1.000000e+00\n",
      "ice_volume_2010             1.310757e-13\n",
      "area_loss_pct_per_decade    1.052240e-13\n",
      "ice_volume_1980            -9.320322e-14\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/glacier_regressor_area_linear_regression.joblib\n",
      "\n",
      "üîç RANDOM_FOREST (area) Regression:\n",
      "üìà RMSE: 15.24 | üìâ MAE: 11.94 | üîÅ R¬≤: 0.8347\n",
      "üìä CV R¬≤: 0.7830 ¬± 0.1999\n",
      "üìå Top Feature Importances:\n",
      "glacier_area_1980             0.298433\n",
      "ice_volume_1980               0.219762\n",
      "glacier_area_2010             0.208467\n",
      "ice_volume_2010               0.167096\n",
      "volume_loss_pct_per_decade    0.033649\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/glacier_regressor_area_random_forest.joblib\n",
      "\n",
      "üîç GRADIENT_BOOSTING (area) Regression:\n",
      "üìà RMSE: 15.87 | üìâ MAE: 13.01 | üîÅ R¬≤: 0.8207\n",
      "üìä CV R¬≤: 0.8194 ¬± 0.0775\n",
      "üìå Top Feature Importances:\n",
      "glacier_area_2010    0.444413\n",
      "ice_volume_1980      0.212890\n",
      "ice_volume_2010      0.162198\n",
      "glacier_area_1980    0.161219\n",
      "min_elev_1980        0.005082\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/glacier_regressor_area_gradient_boosting.joblib\n",
      "\n",
      "‚ùÑÔ∏è Predicting Glacier Volume Loss:\n",
      "\n",
      "üîç LINEAR_REGRESSION (volume) Regression:\n",
      "üìà RMSE: 0.00 | üìâ MAE: 0.00 | üîÅ R¬≤: 1.0000\n",
      "üìä CV R¬≤: 1.0000 ¬± 0.0000\n",
      "üìå Top Coefficients:\n",
      "ice_volume_1980    1.000000e+00\n",
      "ice_volume_2010   -1.000000e+00\n",
      "min_elev_1980      8.278361e-14\n",
      "min_elev_2010     -8.267519e-14\n",
      "elev_rise_m        7.729060e-14\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/glacier_regressor_volume_linear_regression.joblib\n",
      "\n",
      "üîç RANDOM_FOREST (volume) Regression:\n",
      "üìà RMSE: 2.63 | üìâ MAE: 2.07 | üîÅ R¬≤: 0.6562\n",
      "üìä CV R¬≤: 0.6302 ¬± 0.3458\n",
      "üìå Top Feature Importances:\n",
      "glacier_area_1980             0.213635\n",
      "ice_volume_1980               0.185464\n",
      "ice_volume_2010               0.157432\n",
      "volume_loss_pct_per_decade    0.156327\n",
      "glacier_area_2010             0.141496\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/glacier_regressor_volume_random_forest.joblib\n",
      "\n",
      "üîç GRADIENT_BOOSTING (volume) Regression:\n",
      "üìà RMSE: 2.03 | üìâ MAE: 1.71 | üîÅ R¬≤: 0.7945\n",
      "üìä CV R¬≤: 0.6870 ¬± 0.4636\n",
      "üìå Top Feature Importances:\n",
      "ice_volume_1980         0.400230\n",
      "ice_volume_2010         0.267185\n",
      "glacier_area_2010       0.211808\n",
      "glacier_area_1980       0.073701\n",
      "elev_rise_per_decade    0.012583\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/glacier_regressor_volume_gradient_boosting.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- 1. Define targets ---\n",
    "y_area = glacier_features['area_loss_km2']\n",
    "y_volume = glacier_features['volume_loss_km3']\n",
    "\n",
    "# --- 2. Define feature set ---\n",
    "X = glacier_features.drop(columns=[\n",
    "    'area_loss_km2', 'volume_loss_km3', 'retreat_severity',\n",
    "    'area_loss_pct', 'volume_loss_pct',\n",
    "    'basin', 'sub-basin'  # IDs\n",
    "])\n",
    "\n",
    "# --- 3. Drop missing values ---\n",
    "X = X.dropna()\n",
    "y_area = y_area.loc[X.index]\n",
    "y_volume = y_volume.loc[X.index]\n",
    "\n",
    "# --- 4. Train/test split ---\n",
    "X_train, X_test, ya_train, ya_test = train_test_split(X, y_area, test_size=0.25, random_state=42)\n",
    "_, _, yv_train, yv_test = train_test_split(X, y_volume, test_size=0.25, random_state=42)\n",
    "\n",
    "# --- 5. Define models ---\n",
    "models = {\n",
    "    'linear_regression': LinearRegression(),\n",
    "    'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "# --- 6. Evaluation and saving ---\n",
    "def evaluate_and_save_model(name, model, X_train, y_train, X_test, y_test, X_all, y_all, label):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nüîç {name.upper()} ({label}) Regression:\")\n",
    "    print(f\"üìà RMSE: {rmse:.2f} | üìâ MAE: {mae:.2f} | üîÅ R¬≤: {r2:.4f}\")\n",
    "\n",
    "    cv_scores = cross_val_score(model, X_all, y_all, cv=5, scoring='r2')\n",
    "    print(f\"üìä CV R¬≤: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"üìå Top Feature Importances:\")\n",
    "        fi = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(fi.head(5))\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print(\"üìå Top Coefficients:\")\n",
    "        coefs = pd.Series(model.coef_, index=X.columns).sort_values(key=np.abs, ascending=False)\n",
    "        print(coefs.head(5))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Feature importances not available.\")\n",
    "\n",
    "    path = f\"../data/preprocessed/glacier_regressor_{label}_{name}.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"üíæ Model saved to: {path}\")\n",
    "\n",
    "# --- 7. Predict and save for Area Loss ---\n",
    "print(\"\\nüåê Predicting Glacier Area Loss:\")\n",
    "for name, model in models.items():\n",
    "    evaluate_and_save_model(name, model, X_train, ya_train, X_test, ya_test, X, y_area, \"area\")\n",
    "\n",
    "# --- 8. Predict and save for Volume Loss ---\n",
    "print(\"\\n‚ùÑÔ∏è Predicting Glacier Volume Loss:\")\n",
    "for name, model in models.items():\n",
    "    evaluate_and_save_model(name, model, X_train, yv_train, X_test, yv_test, X, y_volume, \"volume\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d150059-9d75-497a-9446-aed52c43d12b",
   "metadata": {},
   "source": [
    "### ‚úÖ Heatwave Days Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11006297-dff3-47ac-95b9-ccf6fe0f410b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Linear Regression Regression:\n",
      "üìà RMSE: 7.13\n",
      "üìâ MAE : 4.53\n",
      "üîÅ R¬≤  : 0.8217\n",
      "üìä CV R¬≤: 0.7362 ¬± 0.1497\n",
      "üìå Top Coefficients:\n",
      "avg_wind                  8.978242\n",
      "temp_range_stddev         5.262960\n",
      "temp_range_stddev_lag1   -4.218279\n",
      "avg_temp_lag1            -2.901453\n",
      "avg_max_temp              2.859666\n",
      "precip_zscore_lag1        1.672863\n",
      "drought_risk_Severe       1.537184\n",
      "precip_zscore            -1.254348\n",
      "drought_risk_None         0.895688\n",
      "highheat_days_lag1        0.713396\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/heatwave_regressor_linear_regression.joblib\n",
      "\n",
      "üîç Random Forest Regression:\n",
      "üìà RMSE: 5.16\n",
      "üìâ MAE : 2.30\n",
      "üîÅ R¬≤  : 0.9068\n",
      "üìä CV R¬≤: 0.8400 ¬± 0.1365\n",
      "üìå Top Feature Importances:\n",
      "avg_max_temp              0.778684\n",
      "highheat_days_lag1        0.072629\n",
      "temp_range_stddev         0.037122\n",
      "avg_temp                  0.032392\n",
      "avg_wind                  0.015560\n",
      "avg_humidity              0.014253\n",
      "avg_temp_lag1             0.009840\n",
      "temp_range_stddev_lag1    0.009381\n",
      "annual_precip_lag1        0.009368\n",
      "precip_zscore             0.007022\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/heatwave_regressor_random_forest.joblib\n",
      "\n",
      "üîç Gradient Boosting Regression:\n",
      "üìà RMSE: 5.15\n",
      "üìâ MAE : 2.56\n",
      "üîÅ R¬≤  : 0.9069\n",
      "üìä CV R¬≤: 0.8424 ¬± 0.1334\n",
      "üìå Top Feature Importances:\n",
      "avg_max_temp              0.737821\n",
      "highheat_days_lag1        0.153114\n",
      "temp_range_stddev         0.041633\n",
      "avg_humidity              0.016393\n",
      "avg_temp                  0.009623\n",
      "temp_range_stddev_lag1    0.008770\n",
      "precip_zscore             0.006324\n",
      "annual_precip_lag1        0.006101\n",
      "annual_precip             0.005857\n",
      "avg_wind                  0.005606\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/heatwave_regressor_gradient_boosting.joblib\n",
      "\n",
      "üìã Regression Model Summary:\n",
      "               Model      RMSE       MAE  R¬≤ Score  CV R¬≤ Mean  CV R¬≤ Std\n",
      "0  linear_regression  7.132995  4.534273  0.821674    0.736235   0.149722\n",
      "1      random_forest  5.155986  2.298387  0.906826    0.840044   0.136509\n",
      "2  gradient_boosting  5.152811  2.557829  0.906941    0.842440   0.133410\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# === Step 0: Ensure output directory exists ===\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "\n",
    "y = climate_yearly['highheat_days']\n",
    "\n",
    "# === Step 2: Define features ===\n",
    "X = climate_yearly.drop(columns=[\n",
    "    'District', 'YEAR', 'highheat_days', 'highheat_year'  # remove ID/leakage\n",
    "])\n",
    "\n",
    "# One-hot encode if any categorical columns exist\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Drop rows with missing data\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# === Step 3: Split data ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# === Step 4: Define models ===\n",
    "models = {\n",
    "    'linear_regression': LinearRegression(),\n",
    "    'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# === Step 5: Train and evaluate ===\n",
    "summary = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç {name.replace('_', ' ').title()} Regression:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"üìà RMSE: {rmse:.2f}\")\n",
    "    print(f\"üìâ MAE : {mae:.2f}\")\n",
    "    print(f\"üîÅ R¬≤  : {r2:.4f}\")\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    print(f\"üìä CV R¬≤: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "\n",
    "    # Feature insights\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"üìå Top Feature Importances:\")\n",
    "        fi = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(fi.head(10))\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print(\"üìå Top Coefficients:\")\n",
    "        coefs = pd.Series(model.coef_, index=X.columns).sort_values(key=np.abs, ascending=False)\n",
    "        print(coefs.head(10))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Feature importances not available.\")\n",
    "\n",
    "    # Save model\n",
    "    model_path = f\"../data/preprocessed/heatwave_regressor_{name}.joblib\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"üíæ Model saved to: {model_path}\")\n",
    "\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R¬≤ Score': r2,\n",
    "        'CV R¬≤ Mean': cv_scores.mean(),\n",
    "        'CV R¬≤ Std': cv_scores.std()\n",
    "    })\n",
    "\n",
    "# === Step 6: Summary Table ===\n",
    "print(\"\\nüìã Regression Model Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a04bb-04f3-40f5-96c9-4129f7cf8b4c",
   "metadata": {},
   "source": [
    "### ‚úÖ Drought Severity Regression using precip_zscore (SPI proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ac79cc1-4ba9-44d0-80f9-f004d56b3dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç LINEAR_REGRESSION Regression:\n",
      "üìà RMSE: 0.1966\n",
      "üìâ MAE : 0.1339\n",
      "üîÅ R¬≤  : 0.9624\n",
      "üìä CV R¬≤: 0.9601 ¬± 0.0123\n",
      "üìå Top Coefficients:\n",
      "precip_zscore_lag1        0.865977\n",
      "temp_range_stddev         0.090480\n",
      "temp_range_stddev_lag1   -0.014425\n",
      "avg_temp_lag1             0.009640\n",
      "avg_max_temp             -0.008935\n",
      "avg_wind                  0.007001\n",
      "avg_humidity              0.006215\n",
      "avg_temp                 -0.005258\n",
      "annual_precip             0.002875\n",
      "annual_precip_lag1       -0.002676\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/drought_regressor_linear_regression.joblib\n",
      "\n",
      "üîç RANDOM_FOREST Regression:\n",
      "üìà RMSE: 0.2321\n",
      "üìâ MAE : 0.1436\n",
      "üîÅ R¬≤  : 0.9476\n",
      "üìä CV R¬≤: 0.9223 ¬± 0.0634\n",
      "üìå Top Feature Importances:\n",
      "annual_precip             0.645946\n",
      "precip_zscore_lag1        0.184665\n",
      "avg_humidity              0.069620\n",
      "annual_precip_lag1        0.021370\n",
      "avg_temp_lag1             0.017162\n",
      "avg_max_temp              0.014386\n",
      "avg_temp                  0.013539\n",
      "avg_wind                  0.012283\n",
      "temp_range_stddev         0.010312\n",
      "temp_range_stddev_lag1    0.008739\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/drought_regressor_random_forest.joblib\n",
      "\n",
      "üîç GRADIENT_BOOSTING Regression:\n",
      "üìà RMSE: 0.2429\n",
      "üìâ MAE : 0.1759\n",
      "üîÅ R¬≤  : 0.9426\n",
      "üìä CV R¬≤: 0.9230 ¬± 0.0498\n",
      "üìå Top Feature Importances:\n",
      "annual_precip             0.614139\n",
      "precip_zscore_lag1        0.232318\n",
      "avg_humidity              0.075419\n",
      "annual_precip_lag1        0.023750\n",
      "avg_max_temp              0.018793\n",
      "temp_range_stddev         0.009816\n",
      "avg_temp_lag1             0.009133\n",
      "avg_temp                  0.006992\n",
      "avg_wind                  0.005143\n",
      "temp_range_stddev_lag1    0.002752\n",
      "dtype: float64\n",
      "üíæ Model saved to: ../data/preprocessed/drought_regressor_gradient_boosting.joblib\n",
      "\n",
      "üìã Regression Model Summary:\n",
      "               Model      RMSE       MAE  R¬≤ Score  CV R¬≤ Mean  CV R¬≤ Std\n",
      "0  linear_regression  0.196566  0.133893  0.962372    0.960062   0.012263\n",
      "1      random_forest  0.232058  0.143619  0.947557    0.922349   0.063384\n",
      "2  gradient_boosting  0.242855  0.175870  0.942564    0.923037   0.049840\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# === Ensure output directory exists ===\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "# === 1. Define target and features ===\n",
    "y = climate_yearly['precip_zscore']  # SPI-like drought index\n",
    "\n",
    "X = climate_yearly.drop(columns=[\n",
    "    'precip_zscore', 'drought_risk', 'highheat_days', 'highheat_year',\n",
    "    'District', 'YEAR'\n",
    "])\n",
    "\n",
    "# Convert categoricals (if any)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Drop rows with missing values\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# === 2. Train/test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# === 3. Define regression models ===\n",
    "models = {\n",
    "    'linear_regression': LinearRegression(),\n",
    "    'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# === 4. Evaluate and save each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîç {name.upper()} Regression:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"üìà RMSE: {rmse:.4f}\")\n",
    "    print(f\"üìâ MAE : {mae:.4f}\")\n",
    "    print(f\"üîÅ R¬≤  : {r2:.4f}\")\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    print(f\"üìä CV R¬≤: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}\")\n",
    "\n",
    "    # Save summary\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R¬≤ Score': r2,\n",
    "        'CV R¬≤ Mean': cv_scores.mean(),\n",
    "        'CV R¬≤ Std': cv_scores.std()\n",
    "    })\n",
    "\n",
    "    # Feature importances / coefficients\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"üìå Top Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(importances.head(10))\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print(\"üìå Top Coefficients:\")\n",
    "        coefs = pd.Series(model.coef_, index=X.columns).sort_values(key=np.abs, ascending=False)\n",
    "        print(coefs.head(10))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Feature importance not available.\")\n",
    "\n",
    "    # Save model\n",
    "    path = f\"../data/preprocessed/drought_regressor_{name}.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"üíæ Model saved to: {path}\")\n",
    "\n",
    "# === 5. Print Summary Table ===\n",
    "print(\"\\nüìã Regression Model Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384eaf6-44a4-451e-9c0f-dad3bdd1b3a2",
   "metadata": {},
   "source": [
    "### üîπ Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661923fc-06b7-47b9-9687-ee7137672644",
   "metadata": {},
   "source": [
    "### ‚úÖ Heatwarve Days Forecasting up to 2050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fb87656-33f3-4cee-b4bd-9a4b494c6e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Forecast Preview (2050):\n",
      "          District  YEAR  predicted_highheat_days\n",
      "30    Arghakhanchi  2050                     12.1\n",
      "61         Baglung  2050                     11.0\n",
      "92         Baitadi  2050                      1.8\n",
      "123         Bajang  2050                      0.5\n",
      "154          Banke  2050                      3.5\n",
      "...            ...   ...                      ...\n",
      "1797       Syangja  2050                      2.0\n",
      "1828       Tanahun  2050                      2.0\n",
      "1859     Taplejung  2050                      4.9\n",
      "1890     Terhathum  2050                      4.9\n",
      "1921      Udayapur  2050                      7.9\n",
      "\n",
      "[62 rows x 3 columns]\n",
      "üíæ Forecast saved to: ../data/preprocessed/highheat_days_forecast_2020_2050.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import os\n",
    "\n",
    "#  input features \n",
    "features = [\n",
    "    'avg_temp', 'avg_max_temp', 'temp_range_stddev', 'avg_humidity',\n",
    "    'avg_wind', 'annual_precip', 'precip_zscore',\n",
    "    'avg_temp_lag1', 'annual_precip_lag1', 'precip_zscore_lag1',\n",
    "    'temp_range_stddev_lag1', 'highheat_days_lag1'\n",
    "]\n",
    "\n",
    "\n",
    "df = climate_yearly.copy()\n",
    "df_model = df[['District', 'YEAR', 'highheat_days'] + features].dropna()\n",
    "\n",
    "X = df_model[features]\n",
    "y = df_model['highheat_days']\n",
    "\n",
    "# === 3. Train model ===\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# === 4. Prepare forecast years and districts ===\n",
    "future_years = list(range(2020, 2051))\n",
    "districts = df_model['District'].unique()\n",
    "forecast_rows = []\n",
    "\n",
    "# === 5. Simulate future values per district ===\n",
    "for district in districts:\n",
    "    district_df = df_model[df_model['District'] == district]\n",
    "    if district_df.empty:\n",
    "        continue\n",
    "\n",
    "    last_row = district_df.loc[district_df['YEAR'].idxmax()].copy()\n",
    "\n",
    "    for year in future_years:\n",
    "        new_row = {'District': district, 'YEAR': year}\n",
    "\n",
    "        for col in features:\n",
    "            if 'lag1' in col:\n",
    "                base_col = col.replace('_lag1', '')\n",
    "                val = last_row.get(base_col, df_model[base_col].mean())\n",
    "                new_row[col] = val\n",
    "            else:\n",
    "                val = last_row.get(col, df_model[col].mean())\n",
    "                new_row[col] = val + np.random.normal(0, 0.1)  # small noise\n",
    "\n",
    "        forecast_rows.append(new_row)\n",
    "        last_row = pd.Series(new_row)\n",
    "\n",
    "# === 6. Predict and output ===\n",
    "forecast_df = pd.DataFrame(forecast_rows)\n",
    "forecast_df = forecast_df.dropna(subset=features)\n",
    "forecast_df['predicted_highheat_days'] = model.predict(forecast_df[features])\n",
    "\n",
    "# === 7. Save output ===\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "forecast_df.to_csv(\"../data/preprocessed/highheat_days_forecast_2020_2050.csv\", index=False)\n",
    "\n",
    "# === 8. Preview ===\n",
    "print(\"‚úÖ Forecast Preview (2050):\")\n",
    "print(forecast_df[forecast_df['YEAR'] == 2050][['District', 'YEAR', 'predicted_highheat_days']].round(1))\n",
    "print(\"üíæ Forecast saved to: ../data/preprocessed/highheat_days_forecast_2020_2050.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a9c4b3-0fd5-4407-9f62-6989790acb66",
   "metadata": {},
   "source": [
    "### ‚úÖ Forecasting Drought Severity to 2050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f54740d-3f3b-41ec-b73f-093cc76ee424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Drought Forecast Preview (2050):\n",
      "          District  YEAR  predicted_spi drought_risk\n",
      "30    Arghakhanchi  2050           1.75         None\n",
      "61         Baglung  2050           1.96         None\n",
      "92         Baitadi  2050           1.13         None\n",
      "123         Bajang  2050           1.11         None\n",
      "154          Banke  2050           1.30         None\n",
      "...            ...   ...            ...          ...\n",
      "1797       Syangja  2050           1.92         None\n",
      "1828       Tanahun  2050           2.62         None\n",
      "1859     Taplejung  2050           1.53         None\n",
      "1890     Terhathum  2050           1.60         None\n",
      "1921      Udayapur  2050           1.30         None\n",
      "\n",
      "[62 rows x 4 columns]\n",
      "üíæ Forecast saved to: ../data/preprocessed/drought_forecast_spi_2020_2050.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import os\n",
    "\n",
    "# Define features used for SPI prediction\n",
    "features = [\n",
    "    'annual_precip', 'avg_temp', 'avg_max_temp', 'avg_humidity',\n",
    "    'avg_wind', 'temp_range_stddev',\n",
    "    'annual_precip_lag1', 'avg_temp_lag1', 'temp_range_stddev_lag1'\n",
    "]\n",
    "target = 'precip_zscore'  # SPI proxy\n",
    "\n",
    "df = climate_yearly.copy()\n",
    "df_model = df[['District', 'YEAR', target] + features].dropna()\n",
    "\n",
    "# Train Gradient Boosting model on historical SPI data ---\n",
    "X = df_model[features]\n",
    "y = df_model[target]\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "#  Forecast SPI for each district from 2020 to 2050 ---\n",
    "future_years = list(range(2020, 2051))\n",
    "districts = df_model['District'].unique()\n",
    "forecast_rows = []\n",
    "\n",
    "for district in districts:\n",
    "    district_df = df_model[df_model['District'] == district].copy()\n",
    "    if district_df.empty:\n",
    "        continue\n",
    "\n",
    "    last_known = district_df[district_df['YEAR'] == district_df['YEAR'].max()]\n",
    "    if last_known.empty:\n",
    "        continue\n",
    "\n",
    "    last_row = last_known.iloc[0].copy()\n",
    "\n",
    "    for year in future_years:\n",
    "        new_row = {'District': district, 'YEAR': year}\n",
    "        for col in features:\n",
    "            if 'lag1' in col:\n",
    "                base_col = col.replace('_lag1', '')\n",
    "                val = last_row.get(base_col, df_model[base_col].mean())\n",
    "                new_row[col] = val\n",
    "            else:\n",
    "                base_val = last_row.get(col, df_model[col].mean())\n",
    "                new_row[col] = base_val + np.random.normal(0, 0.1)\n",
    "        forecast_rows.append(new_row)\n",
    "        last_row = pd.Series(new_row)\n",
    "\n",
    "# --- 5. Predict SPI and classify drought severity ---\n",
    "forecast_df = pd.DataFrame(forecast_rows)\n",
    "forecast_df = forecast_df.dropna(subset=features)\n",
    "forecast_df['predicted_spi'] = model.predict(forecast_df[features])\n",
    "\n",
    "def classify_spi(z):\n",
    "    if z >= -0.5:\n",
    "        return \"None\"\n",
    "    elif z >= -1.0:\n",
    "        return \"Mild\"\n",
    "    elif z >= -1.5:\n",
    "        return \"Moderate\"\n",
    "    elif z >= -2.0:\n",
    "        return \"Severe\"\n",
    "    else:\n",
    "        return \"Extreme\"\n",
    "\n",
    "forecast_df['drought_risk'] = forecast_df['predicted_spi'].apply(classify_spi)\n",
    "\n",
    "# --- 6. Save and preview forecast ---\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "forecast_path = \"../data/preprocessed/drought_forecast_spi_2020_2050.csv\"\n",
    "forecast_df.to_csv(forecast_path, index=False)\n",
    "\n",
    "print(\"‚úÖ Drought Forecast Preview (2050):\")\n",
    "print(forecast_df[forecast_df['YEAR'] == 2050][['District', 'YEAR', 'predicted_spi', 'drought_risk']].round(2))\n",
    "print(f\"üíæ Forecast saved to: {forecast_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d2f2ea-05b8-499c-93aa-29bee7b5439b",
   "metadata": {},
   "source": [
    "### ‚úÖ Climate Forecast Up to 2050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12f0b3dc-289f-4910-a2e4-a358d8a18981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Climate Forecast Preview (2050):\n",
      "          District  YEAR  predicted_avg_temp\n",
      "30    Arghakhanchi  2050               22.62\n",
      "61         Baglung  2050               14.35\n",
      "92         Baitadi  2050                9.96\n",
      "123         Bajang  2050                3.26\n",
      "154          Banke  2050               21.61\n",
      "...            ...   ...                 ...\n",
      "1797       Syangja  2050               18.42\n",
      "1828       Tanahun  2050               12.77\n",
      "1859     Taplejung  2050               12.79\n",
      "1890     Terhathum  2050               13.85\n",
      "1921      Udayapur  2050               22.93\n",
      "\n",
      "[62 rows x 3 columns]\n",
      "üíæ Forecast saved to: ../data/preprocessed/climate_forecast_2020_2050.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import joblib\n",
    "\n",
    "# Define features for forecasting ===\n",
    "features = [\n",
    "    'avg_temp', 'avg_max_temp', 'temp_range_stddev', 'avg_humidity',\n",
    "    'avg_wind', 'annual_precip',\n",
    "    'avg_temp_lag1', 'annual_precip_lag1', 'temp_range_stddev_lag1'\n",
    "]\n",
    "\n",
    "\n",
    "df = climate_yearly.copy()\n",
    "df_model = df[['District', 'YEAR'] + features].dropna()\n",
    "\n",
    "# Train Gradient Boosting model on historical avg_temp ===\n",
    "X = df_model[features]\n",
    "y = df_model['avg_temp']\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Save trained model\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "joblib.dump(model, \"../data/preprocessed/climate_regressor_avg_temp_gradient_boosting.joblib\")\n",
    "\n",
    "# Define forecast range ===\n",
    "future_years = list(range(2020, 2051))\n",
    "districts = df_model['District'].unique()\n",
    "forecast_rows = []\n",
    "\n",
    "#  Forward simulate features by district ===\n",
    "for district in districts:\n",
    "    district_df = df_model[df_model['District'] == district]\n",
    "    if district_df.empty:\n",
    "        continue\n",
    "\n",
    "    last_row = district_df.loc[district_df['YEAR'].idxmax()].copy()\n",
    "\n",
    "    for year in future_years:\n",
    "        new_row = {'District': district, 'YEAR': year}\n",
    "\n",
    "        for col in features:\n",
    "            if 'lag1' in col:\n",
    "                base_col = col.replace('_lag1', '')\n",
    "                val = last_row.get(base_col, df_model[base_col].mean())\n",
    "                new_row[col] = val\n",
    "            else:\n",
    "                val = last_row.get(col, df_model[col].mean())\n",
    "                new_row[col] = val + np.random.normal(0, 0.1)\n",
    "\n",
    "        forecast_rows.append(new_row)\n",
    "        last_row = pd.Series(new_row)\n",
    "\n",
    "# Predict future avg_temp ===\n",
    "forecast_df = pd.DataFrame(forecast_rows)\n",
    "forecast_df = forecast_df.dropna(subset=features)\n",
    "forecast_df['predicted_avg_temp'] = model.predict(forecast_df[features])\n",
    "\n",
    "# Save results ===\n",
    "forecast_path = \"../data/preprocessed/climate_forecast_2020_2050.csv\"\n",
    "forecast_df.to_csv(forecast_path, index=False)\n",
    "\n",
    "# Preview ===\n",
    "print(\"‚úÖ Climate Forecast Preview (2050):\")\n",
    "print(forecast_df[forecast_df['YEAR'] == 2050][['District', 'YEAR', 'predicted_avg_temp']].round(2))\n",
    "print(f\"üíæ Forecast saved to: {forecast_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3f2dcd-5947-404d-ad5d-66b862285e02",
   "metadata": {},
   "source": [
    "### ‚úÖ Glacier Area, Ice Volume, and Minimum Elevation Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89e121c3-9075-4344-877d-06569f6f4a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Glacier Forecast for 2050:\n",
      "    year     basin      sub-basin  predicted_glacier_area  \\\n",
      "57  2050  Mahakali       Mahakali                  110.15   \n",
      "58  2050   Karnali      West Seti                  151.56   \n",
      "59  2050   Karnali         Kawari                   20.03   \n",
      "60  2050   Karnali          Humla                  345.47   \n",
      "61  2050   Karnali           Mugu                  117.08   \n",
      "62  2050   Karnali           Tila                   23.69   \n",
      "63  2050   Karnali          Bheri                  364.77   \n",
      "64  2050   Gandaki   Kali Gandaki                  544.68   \n",
      "65  2050   Gandaki           Seti                   68.43   \n",
      "66  2050   Gandaki     Marsyangdi                  519.82   \n",
      "67  2050   Gandaki  Budhi Gandaki                  347.12   \n",
      "68  2050   Gandaki       Trishuli                  211.47   \n",
      "69  2050     Koshi      Indrawati                    5.39   \n",
      "70  2050     Koshi      Sun Koshi                   58.44   \n",
      "71  2050     Koshi     Tama Koshi                   87.01   \n",
      "72  2050     Koshi          Likhu                   14.93   \n",
      "73  2050     Koshi     Dudh Koshi                  398.47   \n",
      "74  2050     Koshi           Arun                  147.83   \n",
      "75  2050     Koshi          Tamor                  386.73   \n",
      "\n",
      "    predicted_ice_volume  predicted_min_elev  \n",
      "57                  6.98             3712.99  \n",
      "58                  7.62             4126.51  \n",
      "59                  1.17             3701.76  \n",
      "60                 19.25             4268.54  \n",
      "61                  5.94             4461.09  \n",
      "62                  1.20             4129.26  \n",
      "63                 25.09             4122.46  \n",
      "64                 39.26             3828.75  \n",
      "65                  6.93             3844.92  \n",
      "66                 40.98             3681.05  \n",
      "67                 29.21             3285.65  \n",
      "68                 18.96             3667.41  \n",
      "69                  1.26             4782.97  \n",
      "70                  4.29             4051.86  \n",
      "71                  8.24             4353.56  \n",
      "72                  1.17             4281.92  \n",
      "73                 39.30             4402.74  \n",
      "74                 15.14             4205.56  \n",
      "75                 42.54             4171.94  \n",
      "üíæ Forecast saved to: ../data/preprocessed/glacier_forecast_2020_2050.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import os\n",
    "\n",
    "\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "df = glacier_long.copy()\n",
    "\n",
    "# Encode categorical variables ---\n",
    "df['basin_code'] = df['basin'].astype('category').cat.codes\n",
    "df['subbasin_code'] = df['sub-basin'].astype('category').cat.codes\n",
    "\n",
    "# Define input features and target variables ---\n",
    "features = ['year', 'basin_code', 'subbasin_code']\n",
    "targets = ['glacier_area', 'ice_volume', 'min_elev']\n",
    "\n",
    "# Train one model per target ---\n",
    "models = {}\n",
    "for target in targets:\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    models[target] = model\n",
    "\n",
    "# Generate forecast input combinations ---\n",
    "future_years = [2020, 2030, 2040, 2050]\n",
    "basin_info = df[['basin', 'sub-basin', 'basin_code', 'subbasin_code']].drop_duplicates()\n",
    "forecast_rows = []\n",
    "\n",
    "for year in future_years:\n",
    "    for _, row in basin_info.iterrows():\n",
    "        input_dict = {\n",
    "            'year': year,\n",
    "            'basin_code': row['basin_code'],\n",
    "            'subbasin_code': row['subbasin_code']\n",
    "        }\n",
    "        result = {\n",
    "            'year': year,\n",
    "            'basin': row['basin'],\n",
    "            'sub-basin': row['sub-basin']\n",
    "        }\n",
    "        for target in targets:\n",
    "            prediction = models[target].predict(pd.DataFrame([input_dict]))[0]\n",
    "            result[f'predicted_{target}'] = round(float(prediction), 4)\n",
    "        forecast_rows.append(result)\n",
    "\n",
    "# Create forecast DataFrame ---\n",
    "forecast_df = pd.DataFrame(forecast_rows)\n",
    "\n",
    "# Preview and save ---\n",
    "print(\"‚úÖ Glacier Forecast for 2050:\")\n",
    "print(forecast_df[forecast_df['year'] == 2050].round(2))\n",
    "\n",
    "forecast_path = \"../data/preprocessed/glacier_forecast_2020_2050.csv\"\n",
    "forecast_df.to_csv(forecast_path, index=False)\n",
    "print(f\"üíæ Forecast saved to: {forecast_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f859299-9765-4447-92bd-025c9a5f7df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
