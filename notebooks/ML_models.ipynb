{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d77ca492-dde1-4026-b6bc-4845b5a95f3b",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc458886-7d52-47ea-8d9f-4bf2000e9389",
   "metadata": {},
   "source": [
    "### Loading the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f52b8ed-8196-4b74-a79c-7f576cbb38de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load preprocessed feature datasets\n",
    "climate_yearly = pd.read_csv(\"../data/preprocessed/climate_yearly.csv\")\n",
    "merged_with_coords = pd.read_csv(\"../data/preprocessed/merged_with_coords.csv\")\n",
    "merged_scaled = pd.read_csv(\"../data/preprocessed/merged_scaled.csv\")\n",
    "glacier_features = pd.read_csv(\"../data/preprocessed/glacier_features.csv\")\n",
    "glacier_long = pd.read_csv(\"../data/preprocessed/glacier_long.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0995c28-cfb9-4b3d-8df3-0b3dfe5429ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.6.1\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: https://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: BSD 3-Clause License\n",
      "\n",
      " Copyright (c) 2007-2024 The scikit-learn developers.\n",
      " All rights reserved.\n",
      "\n",
      " Redistribution and use in source and binary forms, with or without\n",
      " modification, are permitted provided that the following conditions are met:\n",
      "\n",
      " * Redistributions of source code must retain the above copyright notice, this\n",
      "   list of conditions and the following disclaimer.\n",
      "\n",
      " * Redistributions in binary form must reproduce the above copyright notice,\n",
      "   this list of conditions and the following disclaimer in the documentation\n",
      "   and/or other materials provided with the distribution.\n",
      "\n",
      " * Neither the name of the copyright holder nor the names of its\n",
      "   contributors may be used to endorse or promote products derived from\n",
      "   this software without specific prior written permission.\n",
      "\n",
      " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
      " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
      " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
      " DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE\n",
      " FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
      " DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR\n",
      " SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n",
      " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n",
      " OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n",
      " OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "\n",
      " ----\n",
      "\n",
      " This binary distribution of scikit-learn also bundles the following software:\n",
      "\n",
      " ----\n",
      "\n",
      " Name: Microsoft Visual C++ Runtime Files\n",
      " Files: sklearn\\.libs\\*.dll\n",
      " Availability: https://learn.microsoft.com/en-us/visualstudio/releases/2015/2015-redistribution-vs\n",
      "\n",
      " Subject to the License Terms for the software, you may copy and distribute with your\n",
      " program any of the files within the followng folder and its subfolders except as noted\n",
      " below. You may not modify these files.\n",
      "\n",
      " C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\redist\n",
      "\n",
      " You may not distribute the contents of the following folders:\n",
      "\n",
      " C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\redist\\debug_nonredist\n",
      " C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\redist\\onecore\\debug_nonredist\n",
      "\n",
      " Subject to the License Terms for the software, you may copy and distribute the following\n",
      " files with your program in your programâ€™s application local folder or by deploying them\n",
      " into the Global Assembly Cache (GAC):\n",
      "\n",
      " VC\\atlmfc\\lib\\mfcmifc80.dll\n",
      " VC\\atlmfc\\lib\\amd64\\mfcmifc80.dll\n",
      "\n",
      "Location: C:\\Users\\Wlink\\anaconda3\\Lib\\site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: imbalanced-learn\n"
     ]
    }
   ],
   "source": [
    "!pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65896290-cf5c-4978-a741-a53b447a4306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/Wlink/anaconda3/Lib/site-packages\")\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352bd510-8ce0-4722-a2e8-b37cad854756",
   "metadata": {},
   "source": [
    "### âœ… Climate Zone Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd781d32-00ed-4429-992f-b40e1deb2366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Random Forest Evaluation:\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Alpine       1.00      1.00      1.00        37\n",
      " Subtropical       1.00      1.00      1.00       201\n",
      "   Temperate       1.00      1.00      1.00        88\n",
      "    Tropical       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           1.00       335\n",
      "   macro avg       0.97      1.00      0.99       335\n",
      "weighted avg       1.00      1.00      1.00       335\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[ 37   0   0   0]\n",
      " [  0 200   0   1]\n",
      " [  0   0  88   0]\n",
      " [  0   0   0   9]]\n",
      "ğŸ’¾ Saved to: ../data/preprocessed/climate_zone_random_forest.joblib\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "  avg_temp                       â†’ 0.5167\n",
      "  avg_max_temp                   â†’ 0.3502\n",
      "  temp_range_stddev              â†’ 0.0542\n",
      "  highheat_days                  â†’ 0.0428\n",
      "  annual_precip                  â†’ 0.0239\n",
      "  avg_humidity                   â†’ 0.0122\n",
      "\n",
      "ğŸ” Gradient Boosting Evaluation:\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Alpine       1.00      1.00      1.00        37\n",
      " Subtropical       1.00      1.00      1.00       201\n",
      "   Temperate       1.00      1.00      1.00        88\n",
      "    Tropical       0.90      1.00      0.95         9\n",
      "\n",
      "    accuracy                           1.00       335\n",
      "   macro avg       0.97      1.00      0.99       335\n",
      "weighted avg       1.00      1.00      1.00       335\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[ 37   0   0   0]\n",
      " [  0 200   0   1]\n",
      " [  0   0  88   0]\n",
      " [  0   0   0   9]]\n",
      "ğŸ’¾ Saved to: ../data/preprocessed/climate_zone_gradient_boosting.joblib\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "  avg_temp                       â†’ 0.8179\n",
      "  avg_max_temp                   â†’ 0.1821\n",
      "  highheat_days                  â†’ 0.0000\n",
      "  avg_humidity                   â†’ 0.0000\n",
      "  temp_range_stddev              â†’ -0.0000\n",
      "  annual_precip                  â†’ -0.0000\n",
      "\n",
      "ğŸ” SVM (RBF) Evaluation:\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Alpine       0.90      0.24      0.38        37\n",
      " Subtropical       0.66      0.99      0.79       201\n",
      "   Temperate       0.42      0.11      0.18        88\n",
      "    Tropical       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.65       335\n",
      "   macro avg       0.49      0.34      0.34       335\n",
      "weighted avg       0.61      0.65      0.56       335\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[  9  16  12   0]\n",
      " [  0 199   2   0]\n",
      " [  1  77  10   0]\n",
      " [  0   9   0   0]]\n",
      "ğŸ’¾ Saved to: ../data/preprocessed/climate_zone_svm_rbf.joblib\n",
      "âš ï¸ Feature importances not available.\n",
      "\n",
      "ğŸ“‹ Model Summary:\n",
      "               Model  Test Accuracy  CV Accuracy    CV Std\n",
      "0      Random Forest       0.997015     0.999403  0.001194\n",
      "1  Gradient Boosting       0.997015     0.999403  0.001194\n",
      "2          SVM (RBF)       0.650746     0.653517  0.015394\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- Step 0: Load data and ensure output directory ---\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "try:\n",
    "    merged_with_coords\n",
    "except NameError:\n",
    "    merged_with_coords = pd.read_csv(\"../data/preprocessed/merged_with_coords.csv\")\n",
    "    print(\"âœ… Loaded merged_with_coords.\")\n",
    "\n",
    "# --- Step 1: Assign climate zones if not present ---\n",
    "def assign_climate_zone(row):\n",
    "    if row['avg_temp'] >= 25:\n",
    "        return 'Tropical'\n",
    "    elif row['avg_temp'] >= 15:\n",
    "        return 'Subtropical'\n",
    "    elif row['avg_temp'] >= 5:\n",
    "        return 'Temperate'\n",
    "    else:\n",
    "        return 'Alpine'\n",
    "\n",
    "if 'climate_zone' not in merged_with_coords.columns:\n",
    "    merged_with_coords['climate_zone'] = merged_with_coords.apply(assign_climate_zone, axis=1)\n",
    "\n",
    "# --- Step 2: Define features and target ---\n",
    "features = [\n",
    "    'avg_temp', 'avg_max_temp', 'annual_precip',\n",
    "    'avg_humidity', 'temp_range_stddev', 'highheat_days'\n",
    "]\n",
    "target = 'climate_zone'\n",
    "\n",
    "# Drop rows with missing values\n",
    "data = merged_with_coords.dropna(subset=features + [target]).copy()\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# --- Step 3: Split data ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- Step 4: Define models ---\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM (RBF)': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# --- Step 5: Train, Evaluate, Save ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸ” {name} Evaluation:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"âœ… Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    print(\"ğŸ“‰ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': model.score(X_test, y_test),\n",
    "        'CV Accuracy': np.mean(cv),\n",
    "        'CV Std': np.std(cv)\n",
    "    })\n",
    "\n",
    "    # Save trained model\n",
    "    model_key = name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "    filename = f\"../data/preprocessed/climate_zone_{model_key}.joblib\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"ğŸ’¾ Saved to: {filename}\")\n",
    "\n",
    "    # Show feature importances if available\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"ğŸ“Œ Top Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        for feat, score in importances.items():\n",
    "            print(f\"  {feat:<30} â†’ {score:.4f}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Feature importances not available.\")\n",
    "\n",
    "# --- Step 6: Summary ---\n",
    "print(\"\\nğŸ“‹ Model Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d039d3-837d-4531-afe7-64f0a42c9d49",
   "metadata": {},
   "source": [
    "### âœ… Extreme Heat Classification based on district-year climate conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "243e2864-e0fe-4ae5-a454-145dfd302681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” RANDOM_FOREST Evaluation\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       527\n",
      "           1       0.92      0.73      0.81        62\n",
      "\n",
      "    accuracy                           0.96       589\n",
      "   macro avg       0.94      0.86      0.90       589\n",
      "weighted avg       0.96      0.96      0.96       589\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[523   4]\n",
      " [ 17  45]]\n",
      "ğŸ“Œ Feature Importances:\n",
      "avg_max_temp              0.277068\n",
      "avg_temp                  0.161855\n",
      "highheat_days_lag1        0.142808\n",
      "avg_temp_lag1             0.101432\n",
      "temp_range_stddev         0.076850\n",
      "avg_wind                  0.040485\n",
      "temp_range_stddev_lag1    0.039728\n",
      "avg_humidity              0.039708\n",
      "annual_precip             0.033616\n",
      "precip_zscore             0.031232\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/heatwave_model_random_forest.joblib\n",
      "\n",
      "ğŸ” GRADIENT_BOOSTING Evaluation\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       527\n",
      "           1       0.85      0.76      0.80        62\n",
      "\n",
      "    accuracy                           0.96       589\n",
      "   macro avg       0.91      0.87      0.89       589\n",
      "weighted avg       0.96      0.96      0.96       589\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[519   8]\n",
      " [ 15  47]]\n",
      "ğŸ“Œ Feature Importances:\n",
      "avg_max_temp              0.677379\n",
      "highheat_days_lag1        0.079987\n",
      "temp_range_stddev         0.062567\n",
      "annual_precip             0.039872\n",
      "avg_temp                  0.030724\n",
      "avg_wind                  0.025214\n",
      "avg_temp_lag1             0.024698\n",
      "avg_humidity              0.023164\n",
      "temp_range_stddev_lag1    0.011759\n",
      "annual_precip_lag1        0.008437\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/heatwave_model_gradient_boosting.joblib\n",
      "\n",
      "ğŸ” SVM_RBF Evaluation\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       527\n",
      "           1       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.89       589\n",
      "   macro avg       0.45      0.50      0.47       589\n",
      "weighted avg       0.80      0.89      0.85       589\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[527   0]\n",
      " [ 62   0]]\n",
      "âš ï¸ Feature importances not available for this model.\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/heatwave_model_svm_rbf.joblib\n",
      "\n",
      "ğŸ“‹ Model Performance Summary:\n",
      "               Model  Test Accuracy  CV Accuracy    CV Std\n",
      "0      random_forest       0.964346     0.955441  0.023962\n",
      "1  gradient_boosting       0.960951     0.954596  0.026504\n",
      "2            svm_rbf       0.894737     0.895162  0.000988\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Define binary heatwave label\n",
    "threshold = 30\n",
    "climate_yearly['highheat_year'] = (climate_yearly['highheat_days'] >= threshold).astype(int)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = climate_yearly.drop(columns=[\n",
    "    'District', 'YEAR', 'highheat_days', 'highheat_year'\n",
    "])\n",
    "X = X.select_dtypes(include=[np.number]).dropna()\n",
    "y = climate_yearly.loc[X.index, 'highheat_year']\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'svm_rbf': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "summary = []\n",
    "\n",
    "# Train, Evaluate, Save\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸ” {name.upper()} Evaluation\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"âœ… Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print(\"ğŸ“‰ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Cross-validation\n",
    "    cv = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': model.score(X_test, y_test),\n",
    "        'CV Accuracy': np.mean(cv),\n",
    "        'CV Std': np.std(cv)\n",
    "    })\n",
    "\n",
    "    # Feature importances (for tree-based models)\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        print(\"ğŸ“Œ Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(importances.head(10))\n",
    "    else:\n",
    "        print(\"âš ï¸ Feature importances not available for this model.\")\n",
    "\n",
    "    # Save model\n",
    "    path = f\"../data/preprocessed/heatwave_model_{name}.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"ğŸ’¾ Model saved to: {path}\")\n",
    "\n",
    "# === Step 8: Summary ===\n",
    "print(\"\\nğŸ“‹ Model Performance Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a94264-5953-44e3-9409-b32656bb555a",
   "metadata": {},
   "source": [
    "### âœ… Drought Risk Category Classification using existing SPI proxy (precip_zscore) in climate_yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f051617f-9256-42d6-a78f-d68e69a5666a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” RANDOM_FOREST Evaluation\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Mild       1.00      1.00      1.00       107\n",
      "    Moderate       1.00      1.00      1.00       110\n",
      "        None       1.00      1.00      1.00       357\n",
      "      Severe       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00       589\n",
      "   macro avg       1.00      1.00      1.00       589\n",
      "weighted avg       1.00      1.00      1.00       589\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[107   0   0   0]\n",
      " [  0 110   0   0]\n",
      " [  0   0 357   0]\n",
      " [  0   0   0  15]]\n",
      "ğŸ“Œ Feature Importances:\n",
      "precip_zscore         0.526629\n",
      "annual_precip         0.146229\n",
      "precip_zscore_lag1    0.099228\n",
      "avg_humidity          0.070069\n",
      "annual_precip_lag1    0.040478\n",
      "temp_range_stddev     0.025521\n",
      "avg_wind              0.023295\n",
      "avg_max_temp          0.020182\n",
      "avg_temp_lag1         0.019290\n",
      "avg_temp              0.014792\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/drought_model_random_forest.joblib\n",
      "\n",
      "ğŸ” GRADIENT_BOOSTING Evaluation\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Mild       1.00      1.00      1.00       107\n",
      "    Moderate       1.00      1.00      1.00       110\n",
      "        None       1.00      1.00      1.00       357\n",
      "      Severe       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00       589\n",
      "   macro avg       1.00      1.00      1.00       589\n",
      "weighted avg       1.00      1.00      1.00       589\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[107   0   0   0]\n",
      " [  0 110   0   0]\n",
      " [  0   0 357   0]\n",
      " [  0   0   0  15]]\n",
      "ğŸ“Œ Feature Importances:\n",
      "precip_zscore             1.000000e+00\n",
      "temp_range_stddev_lag1    1.458950e-15\n",
      "precip_zscore_lag1        1.049373e-15\n",
      "avg_max_temp              8.347656e-16\n",
      "avg_temp_lag1             6.526929e-16\n",
      "avg_temp                  4.085518e-16\n",
      "avg_humidity              1.227044e-16\n",
      "highheat_days_lag1        4.014548e-17\n",
      "temp_range_stddev         2.304032e-17\n",
      "annual_precip_lag1        6.466733e-18\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/drought_model_gradient_boosting.joblib\n",
      "\n",
      "ğŸ” SVM_RBF Evaluation\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Mild       0.48      0.38      0.43       107\n",
      "    Moderate       0.56      0.72      0.63       110\n",
      "        None       0.89      0.90      0.90       357\n",
      "      Severe       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.75       589\n",
      "   macro avg       0.48      0.50      0.49       589\n",
      "weighted avg       0.73      0.75      0.74       589\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[ 41  32  34   0]\n",
      " [ 24  79   7   0]\n",
      " [ 19  15 323   0]\n",
      " [  1  14   0   0]]\n",
      "âš ï¸ Feature importances not available for this model.\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/drought_model_svm_rbf.joblib\n",
      "\n",
      "ğŸ“‹ Model Performance Summary:\n",
      "               Model  Test Accuracy  CV Accuracy    CV Std\n",
      "0      random_forest       1.000000     0.998301  0.001589\n",
      "1  gradient_boosting       1.000000     1.000000  0.000000\n",
      "2            svm_rbf       0.752122     0.734712  0.040177\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# --- Step 1: Ensure output directory exists ---\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "# --- Step 2: Classify drought risk based on SPI-like z-score ---\n",
    "def classify_spi(z):\n",
    "    if z >= -0.5:\n",
    "        return \"None\"\n",
    "    elif z >= -1.0:\n",
    "        return \"Mild\"\n",
    "    elif z >= -1.5:\n",
    "        return \"Moderate\"\n",
    "    elif z >= -2.0:\n",
    "        return \"Severe\"\n",
    "    else:\n",
    "        return \"Extreme\"\n",
    "\n",
    "climate_yearly['drought_risk'] = climate_yearly['precip_zscore'].apply(classify_spi)\n",
    "\n",
    "# --- Step 3: Define features and target ---\n",
    "X = climate_yearly.drop(columns=[\n",
    "    'highheat_days', 'highheat_year', 'drought_risk',\n",
    "    'District', 'YEAR'\n",
    "])\n",
    "X = X.select_dtypes(include=[np.number]).dropna()\n",
    "y = climate_yearly.loc[X.index, 'drought_risk']\n",
    "\n",
    "# --- Step 4: Encode target labels ---\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# --- Step 5: Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.25, stratify=y_encoded, random_state=42\n",
    ")\n",
    "\n",
    "# --- Step 6: Define classifiers ---\n",
    "models = {\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'svm_rbf': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# --- Step 7: Train, evaluate, and save ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸ” {name.upper()} Evaluation\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"âœ… Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))\n",
    "\n",
    "    print(\"ğŸ“‰ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y_encoded, cv=5, scoring='accuracy')\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': model.score(X_test, y_test),\n",
    "        'CV Accuracy': np.mean(cv_scores),\n",
    "        'CV Std': np.std(cv_scores)\n",
    "    })\n",
    "\n",
    "    # Feature importances\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"ğŸ“Œ Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(importances.head(10))\n",
    "    else:\n",
    "        print(\"âš ï¸ Feature importances not available for this model.\")\n",
    "\n",
    "    # Save model\n",
    "    path = f\"../data/preprocessed/drought_model_{name}.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"ğŸ’¾ Model saved to: {path}\")\n",
    "\n",
    "# --- Step 8: Print Summary ---\n",
    "print(\"\\nğŸ“‹ Model Performance Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575a643a-dee5-41fd-832f-106009877ae4",
   "metadata": {},
   "source": [
    "### âœ… Cereal Yield Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee4af223-a63d-4ab9-9065-5f69a9eb9823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” RANDOM_FOREST Evaluation:\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00        48\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[ 6  0]\n",
      " [ 0 48]]\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/yield_model_random_forest.joblib\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "total_yield_minmax    0.156975\n",
      "total_yield_zscore    0.106118\n",
      "pd_minmax             0.081320\n",
      "pd_zscore             0.069197\n",
      "mz                    0.051258\n",
      "pd                    0.049521\n",
      "mz_minmax             0.047322\n",
      "pd_ma3                0.047286\n",
      "pd_ma3_zscore         0.036526\n",
      "pd_ma3_minmax         0.029252\n",
      "dtype: float64\n",
      "\n",
      "ğŸ” GRADIENT_BOOSTING Evaluation:\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00        48\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[ 6  0]\n",
      " [ 0 48]]\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/yield_model_gradient_boosting.joblib\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "total_yield_zscore    0.610047\n",
      "total_yield_minmax    0.389953\n",
      "bl                    0.000000\n",
      "mz                    0.000000\n",
      "pd                    0.000000\n",
      "bw                    0.000000\n",
      "ml                    0.000000\n",
      "pd_change             0.000000\n",
      "wt_change             0.000000\n",
      "mz_ma3                0.000000\n",
      "dtype: float64\n",
      "\n",
      "ğŸ” SVM_RBF Evaluation:\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.67      0.80         6\n",
      "           1       0.96      1.00      0.98        48\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.98      0.83      0.89        54\n",
      "weighted avg       0.96      0.96      0.96        54\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[ 4  2]\n",
      " [ 0 48]]\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/yield_model_svm_rbf.joblib\n",
      "âš ï¸ Feature importances not available for this model.\n",
      "\n",
      "ğŸ“‹ Model Summary:\n",
      "               Model  Test Accuracy  CV Accuracy    CV Std\n",
      "0      random_forest       1.000000     0.986152  0.011308\n",
      "1  gradient_boosting       1.000000     0.990803  0.011265\n",
      "2            svm_rbf       0.962963     0.958457  0.026800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Ensure output directory exists \n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "# Create Binary Yield Label\n",
    "threshold = merged_scaled['total_yield'].median()\n",
    "merged_scaled['yield_class'] = (merged_scaled['total_yield'] > threshold).astype(int)\n",
    "\n",
    "# Define Features and Labels\n",
    "X_raw = merged_scaled.drop(columns=[\n",
    "    'total_yield', 'yield_class', 'district_name', 'year',\n",
    "    'CENTROID_LAT', 'CENTROID_LON'\n",
    "])\n",
    "\n",
    "X = pd.get_dummies(X_raw, drop_first=True)\n",
    "y = merged_scaled['yield_class']\n",
    "\n",
    "# Drop rows with missing values\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# Define and Train Models\n",
    "models = {\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'svm_rbf': SVC(kernel='rbf', probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# Train, Evaluate, Save\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸ” {name.upper()} Evaluation:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"âœ… Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "    print(\"ğŸ“‰ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': model.score(X_test, y_test),\n",
    "        'CV Accuracy': np.mean(cv_scores),\n",
    "        'CV Std': np.std(cv_scores)\n",
    "    })\n",
    "\n",
    "    # Save model\n",
    "    model_path = f\"../data/preprocessed/yield_model_{name}.joblib\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"ğŸ’¾ Model saved to: {model_path}\")\n",
    "\n",
    "    # Feature importance\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"ğŸ“Œ Top Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(importances.head(10))\n",
    "    else:\n",
    "        print(\"âš ï¸ Feature importances not available for this model.\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nğŸ“‹ Model Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb1b938-20c7-4ec3-a87e-69c1601a195b",
   "metadata": {},
   "source": [
    "#### âœ… Glacier Retreat Severity Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8db73b3-da7b-48cc-abe8-2a385f7c8680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” RANDOM_FOREST Evaluation:\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      0.50      0.67         2\n",
      "    Moderate       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.80         5\n",
      "   macro avg       0.88      0.75      0.76         5\n",
      "weighted avg       0.85      0.80      0.78         5\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[1 1]\n",
      " [0 3]]\n",
      "ğŸ“Š 5-Fold CV Accuracy: 0.900 Â± 0.200\n",
      "ğŸ“Œ Feature Importances:\n",
      "  area_loss_pct             â†’ 0.2681\n",
      "  volume_loss_pct           â†’ 0.1742\n",
      "  ice_volume_2010           â†’ 0.1469\n",
      "  ice_volume_1980           â†’ 0.0842\n",
      "  glacier_area_2010         â†’ 0.0779\n",
      "  glacier_area_1980         â†’ 0.0748\n",
      "  volume_loss_km3           â†’ 0.0693\n",
      "  min_elev_1980             â†’ 0.0427\n",
      "  min_elev_2010             â†’ 0.0323\n",
      "  area_loss_km2             â†’ 0.0252\n",
      "  elev_rise_m               â†’ 0.0044\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/glacier_model_random_forest.joblib\n",
      "\n",
      "ğŸ” SVM_RBF Evaluation:\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.00      0.00      0.00         2\n",
      "    Moderate       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.30      0.50      0.38         5\n",
      "weighted avg       0.36      0.60      0.45         5\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[0 2]\n",
      " [0 3]]\n",
      "ğŸ“Š 5-Fold CV Accuracy: 0.683 Â± 0.097\n",
      "âš ï¸ Feature importance not available for this model.\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/glacier_model_svm_rbf.joblib\n",
      "\n",
      "ğŸ” GRADIENT_BOOSTING Evaluation:\n",
      "âœ… Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      1.00      1.00         2\n",
      "    Moderate       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         5\n",
      "   macro avg       1.00      1.00      1.00         5\n",
      "weighted avg       1.00      1.00      1.00         5\n",
      "\n",
      "ğŸ“‰ Confusion Matrix:\n",
      "[[2 0]\n",
      " [0 3]]\n",
      "ğŸ“Š 5-Fold CV Accuracy: 0.850 Â± 0.200\n",
      "ğŸ“Œ Feature Importances:\n",
      "  area_loss_pct             â†’ 1.0000\n",
      "  glacier_area_2010         â†’ 0.0000\n",
      "  glacier_area_1980         â†’ 0.0000\n",
      "  ice_volume_1980           â†’ 0.0000\n",
      "  ice_volume_2010           â†’ 0.0000\n",
      "  min_elev_2010             â†’ 0.0000\n",
      "  min_elev_1980             â†’ 0.0000\n",
      "  area_loss_km2             â†’ 0.0000\n",
      "  volume_loss_km3           â†’ 0.0000\n",
      "  volume_loss_pct           â†’ 0.0000\n",
      "  elev_rise_m               â†’ 0.0000\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/glacier_model_gradient_boosting.joblib\n",
      "\n",
      "ğŸ“‹ Summary Comparison:\n",
      "               Model  Test Accuracy  CV Accuracy Mean  CV Accuracy Std\n",
      "0      random_forest            0.8          0.900000         0.200000\n",
      "1            svm_rbf            0.6          0.683333         0.097183\n",
      "2  gradient_boosting            1.0          0.850000         0.200000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- Step 0: Ensure output directory exists ---\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "\n",
    "X = glacier_features[[\n",
    "    'glacier_area_1980', 'glacier_area_2010',\n",
    "    'ice_volume_1980', 'ice_volume_2010',\n",
    "    'min_elev_1980', 'min_elev_2010',\n",
    "    'area_loss_km2', 'area_loss_pct',\n",
    "    'volume_loss_km3', 'volume_loss_pct',\n",
    "    'elev_rise_m'\n",
    "]]\n",
    "y = glacier_features['retreat_severity']\n",
    "\n",
    "# --- Step 2: Train/test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# --- Step 3: Models ---\n",
    "models = {\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'svm_rbf': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# --- Step 4: Train, evaluate, and save models ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸ” {name.upper()} Evaluation:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Report\n",
    "    print(\"âœ… Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    print(\"ğŸ“‰ Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    # CV Score\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "    cv_mean, cv_std = scores.mean(), scores.std()\n",
    "    print(f\"ğŸ“Š 5-Fold CV Accuracy: {cv_mean:.3f} Â± {cv_std:.3f}\")\n",
    "\n",
    "    # Feature importances\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        print(\"ğŸ“Œ Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        for feat, val in importances.items():\n",
    "            print(f\"  {feat:<25} â†’ {val:.4f}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Feature importance not available for this model.\")\n",
    "\n",
    "    # Save model\n",
    "    model_path = f\"../data/preprocessed/glacier_model_{name}.joblib\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"ğŸ’¾ Model saved to: {model_path}\")\n",
    "\n",
    "    # Add to summary\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': model.score(X_test, y_test),\n",
    "        'CV Accuracy Mean': cv_mean,\n",
    "        'CV Accuracy Std': cv_std\n",
    "    })\n",
    "\n",
    "# --- Step 5: Summary Table ---\n",
    "print(\"\\nğŸ“‹ Summary Comparison:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba0367a-440f-40a2-9dc6-a67cdc006526",
   "metadata": {},
   "source": [
    "### ğŸ”¹ Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bef07a-ee7e-407c-8fe4-6cafeee5bb39",
   "metadata": {},
   "source": [
    "### âœ… Cereal Yield Prediction (Regression Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "767314fc-3578-445a-9477-21e83650cac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Linear Regression Evaluation:\n",
      "ğŸ“ˆ RMSE: 0.00\n",
      "ğŸ“‰ MAE : 0.00\n",
      "ğŸ” RÂ²  : 1.0000\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/yield_regressor_linear_regression.joblib\n",
      "ğŸ“Œ Top Coefficients:\n",
      "mz                    0.666665\n",
      "pd                    0.666665\n",
      "wt                    0.666665\n",
      "pd_lag1               0.333333\n",
      "mz_change             0.333333\n",
      "mz_lag1               0.333332\n",
      "wt_change             0.333332\n",
      "wt_lag1               0.333332\n",
      "pd_change             0.333332\n",
      "total_yield_zscore    0.001069\n",
      "dtype: float64\n",
      "\n",
      "ğŸ” Ridge Regression Evaluation:\n",
      "ğŸ“ˆ RMSE: 0.00\n",
      "ğŸ“‰ MAE : 0.00\n",
      "ğŸ” RÂ²  : 1.0000\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/yield_regressor_ridge_regression.joblib\n",
      "ğŸ“Œ Top Coefficients:\n",
      "mz                    0.666665\n",
      "pd                    0.666665\n",
      "wt                    0.666665\n",
      "pd_lag1               0.333333\n",
      "mz_change             0.333333\n",
      "mz_lag1               0.333332\n",
      "wt_change             0.333332\n",
      "wt_lag1               0.333332\n",
      "pd_change             0.333332\n",
      "total_yield_zscore    0.001069\n",
      "dtype: float64\n",
      "\n",
      "ğŸ” Lasso Regression Evaluation:\n",
      "ğŸ“ˆ RMSE: 0.67\n",
      "ğŸ“‰ MAE : 0.52\n",
      "ğŸ” RÂ²  : 1.0000\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/yield_regressor_lasso_regression.joblib\n",
      "ğŸ“Œ Top Coefficients:\n",
      "bl_zscore           358.582565\n",
      "bw_zscore           326.802877\n",
      "mz_ma3_zscore       147.694931\n",
      "mz_zscore          -133.910733\n",
      "wt_zscore           113.906443\n",
      "mz_lag1_zscore      -81.840284\n",
      "pd_zscore            62.757294\n",
      "ml_zscore           -45.836502\n",
      "mz_change_zscore    -32.327958\n",
      "wt_change_zscore     30.766079\n",
      "dtype: float64\n",
      "\n",
      "ğŸ” Random Forest Evaluation:\n",
      "ğŸ“ˆ RMSE: 129.39\n",
      "ğŸ“‰ MAE : 74.05\n",
      "ğŸ” RÂ²  : 0.9957\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/yield_regressor_random_forest.joblib\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "total_yield_zscore    0.467576\n",
      "total_yield_minmax    0.460087\n",
      "pd                    0.016834\n",
      "pd_zscore             0.007980\n",
      "pd_minmax             0.007171\n",
      "pd_ma3                0.003031\n",
      "pd_ma3_zscore         0.002445\n",
      "mz_zscore             0.002130\n",
      "wt                    0.001799\n",
      "pd_ma3_minmax         0.001621\n",
      "dtype: float64\n",
      "\n",
      "ğŸ” Gradient Boosting Evaluation:\n",
      "ğŸ“ˆ RMSE: 72.73\n",
      "ğŸ“‰ MAE : 41.00\n",
      "ğŸ” RÂ²  : 0.9987\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/yield_regressor_gradient_boosting.joblib\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "total_yield_zscore    0.590704\n",
      "total_yield_minmax    0.402175\n",
      "mz_zscore             0.001773\n",
      "bl_zscore             0.001600\n",
      "ml                    0.000827\n",
      "bl                    0.000809\n",
      "bl_minmax             0.000775\n",
      "mz_ma3_zscore         0.000419\n",
      "mz                    0.000338\n",
      "wt_ma3_zscore         0.000300\n",
      "dtype: float64\n",
      "\n",
      "ğŸ“‹ Regression Model Summary:\n",
      "               Model          RMSE           MAE  RÂ² Score  CV RÂ² Mean  \\\n",
      "0  linear_regression  4.107204e-12  3.056913e-12  1.000000    1.000000   \n",
      "1   ridge_regression  2.677706e-05  2.103500e-05  1.000000    1.000000   \n",
      "2   lasso_regression  6.727233e-01  5.205736e-01  1.000000    1.000000   \n",
      "3      random_forest  1.293949e+02  7.404778e+01  0.995748    0.971478   \n",
      "4  gradient_boosting  7.273157e+01  4.100111e+01  0.998657    0.991604   \n",
      "\n",
      "      CV RÂ² Std  \n",
      "0  0.000000e+00  \n",
      "1  1.110223e-16  \n",
      "2  1.347981e-07  \n",
      "3  2.859690e-02  \n",
      "4  5.181846e-03  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# --- Step 0: Ensure output directory exists ---\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "y = merged_scaled['total_yield']\n",
    "X_raw = merged_scaled.drop(columns=[\n",
    "    'total_yield', 'yield_class', 'district_name', 'year',\n",
    "    'CENTROID_LAT', 'CENTROID_LON'\n",
    "])\n",
    "X = pd.get_dummies(X_raw, drop_first=True)\n",
    "\n",
    "# --- Step 2: Drop missing values ---\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# --- Step 3: Train-test split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# --- Step 4: Define regression models ---\n",
    "models = {\n",
    "    'linear_regression': LinearRegression(),\n",
    "    'ridge_regression': Ridge(alpha=1.0),\n",
    "    'lasso_regression': Lasso(alpha=0.1),\n",
    "    'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# --- Step 5: Train, Evaluate, Save ---\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸ” {name.replace('_', ' ').title()} Evaluation:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"ğŸ“ˆ RMSE: {rmse:.2f}\")\n",
    "    print(f\"ğŸ“‰ MAE : {mae:.2f}\")\n",
    "    print(f\"ğŸ” RÂ²  : {r2:.4f}\")\n",
    "\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'RÂ² Score': r2,\n",
    "        'CV RÂ² Mean': np.mean(cv_scores),\n",
    "        'CV RÂ² Std': np.std(cv_scores)\n",
    "    })\n",
    "\n",
    "    # Save model to disk\n",
    "    model_path = f\"../data/preprocessed/yield_regressor_{name}.joblib\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"ğŸ’¾ Model saved to: {model_path}\")\n",
    "\n",
    "    # Display feature importance or coefficients\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"ğŸ“Œ Top Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(importances.head(10))\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print(\"ğŸ“Œ Top Coefficients:\")\n",
    "        coefs = pd.Series(model.coef_, index=X.columns).sort_values(key=np.abs, ascending=False)\n",
    "        print(coefs.head(10))\n",
    "    else:\n",
    "        print(\"âš ï¸ Feature importance not available.\")\n",
    "\n",
    "# --- Step 6: Print summary ---\n",
    "print(\"\\nğŸ“‹ Regression Model Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8732091-1fdf-4e54-bc66-2b5b84e9d86e",
   "metadata": {},
   "source": [
    "### âœ… Glacier Area and Volume Loss Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "718b4810-b0a0-4c8e-ae68-8536ef560746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸŒ Predicting Glacier Area Loss:\n",
      "\n",
      "ğŸ” LINEAR_REGRESSION (area) Regression:\n",
      "ğŸ“ˆ RMSE: 0.00 | ğŸ“‰ MAE: 0.00 | ğŸ” RÂ²: 1.0000\n",
      "ğŸ“Š CV RÂ²: 1.0000 Â± 0.0000\n",
      "ğŸ“Œ Top Coefficients:\n",
      "glacier_area_1980          -1.000000e+00\n",
      "glacier_area_2010           1.000000e+00\n",
      "ice_volume_2010             1.310757e-13\n",
      "area_loss_pct_per_decade    1.052240e-13\n",
      "ice_volume_1980            -9.320322e-14\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/glacier_regressor_area_linear_regression.joblib\n",
      "\n",
      "ğŸ” RANDOM_FOREST (area) Regression:\n",
      "ğŸ“ˆ RMSE: 15.24 | ğŸ“‰ MAE: 11.94 | ğŸ” RÂ²: 0.8347\n",
      "ğŸ“Š CV RÂ²: 0.7830 Â± 0.1999\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "glacier_area_1980             0.298433\n",
      "ice_volume_1980               0.219762\n",
      "glacier_area_2010             0.208467\n",
      "ice_volume_2010               0.167096\n",
      "volume_loss_pct_per_decade    0.033649\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/glacier_regressor_area_random_forest.joblib\n",
      "\n",
      "ğŸ” GRADIENT_BOOSTING (area) Regression:\n",
      "ğŸ“ˆ RMSE: 15.87 | ğŸ“‰ MAE: 13.01 | ğŸ” RÂ²: 0.8207\n",
      "ğŸ“Š CV RÂ²: 0.8194 Â± 0.0775\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "glacier_area_2010    0.444413\n",
      "ice_volume_1980      0.212890\n",
      "ice_volume_2010      0.162198\n",
      "glacier_area_1980    0.161219\n",
      "min_elev_1980        0.005082\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/glacier_regressor_area_gradient_boosting.joblib\n",
      "\n",
      "â„ï¸ Predicting Glacier Volume Loss:\n",
      "\n",
      "ğŸ” LINEAR_REGRESSION (volume) Regression:\n",
      "ğŸ“ˆ RMSE: 0.00 | ğŸ“‰ MAE: 0.00 | ğŸ” RÂ²: 1.0000\n",
      "ğŸ“Š CV RÂ²: 1.0000 Â± 0.0000\n",
      "ğŸ“Œ Top Coefficients:\n",
      "ice_volume_1980    1.000000e+00\n",
      "ice_volume_2010   -1.000000e+00\n",
      "min_elev_1980      8.278361e-14\n",
      "min_elev_2010     -8.267519e-14\n",
      "elev_rise_m        7.729060e-14\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/glacier_regressor_volume_linear_regression.joblib\n",
      "\n",
      "ğŸ” RANDOM_FOREST (volume) Regression:\n",
      "ğŸ“ˆ RMSE: 2.63 | ğŸ“‰ MAE: 2.07 | ğŸ” RÂ²: 0.6562\n",
      "ğŸ“Š CV RÂ²: 0.6302 Â± 0.3458\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "glacier_area_1980             0.213635\n",
      "ice_volume_1980               0.185464\n",
      "ice_volume_2010               0.157432\n",
      "volume_loss_pct_per_decade    0.156327\n",
      "glacier_area_2010             0.141496\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/glacier_regressor_volume_random_forest.joblib\n",
      "\n",
      "ğŸ” GRADIENT_BOOSTING (volume) Regression:\n",
      "ğŸ“ˆ RMSE: 2.03 | ğŸ“‰ MAE: 1.71 | ğŸ” RÂ²: 0.7945\n",
      "ğŸ“Š CV RÂ²: 0.6870 Â± 0.4636\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "ice_volume_1980         0.400230\n",
      "ice_volume_2010         0.267185\n",
      "glacier_area_2010       0.211808\n",
      "glacier_area_1980       0.073701\n",
      "elev_rise_per_decade    0.012583\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/glacier_regressor_volume_gradient_boosting.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# --- 1. Define targets ---\n",
    "y_area = glacier_features['area_loss_km2']\n",
    "y_volume = glacier_features['volume_loss_km3']\n",
    "\n",
    "# --- 2. Define feature set ---\n",
    "X = glacier_features.drop(columns=[\n",
    "    'area_loss_km2', 'volume_loss_km3', 'retreat_severity',\n",
    "    'area_loss_pct', 'volume_loss_pct',\n",
    "    'basin', 'sub-basin'  # IDs\n",
    "])\n",
    "\n",
    "# --- 3. Drop missing values ---\n",
    "X = X.dropna()\n",
    "y_area = y_area.loc[X.index]\n",
    "y_volume = y_volume.loc[X.index]\n",
    "\n",
    "# --- 4. Train/test split ---\n",
    "X_train, X_test, ya_train, ya_test = train_test_split(X, y_area, test_size=0.25, random_state=42)\n",
    "_, _, yv_train, yv_test = train_test_split(X, y_volume, test_size=0.25, random_state=42)\n",
    "\n",
    "# --- 5. Define models ---\n",
    "models = {\n",
    "    'linear_regression': LinearRegression(),\n",
    "    'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "# --- 6. Evaluation and saving ---\n",
    "def evaluate_and_save_model(name, model, X_train, y_train, X_test, y_test, X_all, y_all, label):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\nğŸ” {name.upper()} ({label}) Regression:\")\n",
    "    print(f\"ğŸ“ˆ RMSE: {rmse:.2f} | ğŸ“‰ MAE: {mae:.2f} | ğŸ” RÂ²: {r2:.4f}\")\n",
    "\n",
    "    cv_scores = cross_val_score(model, X_all, y_all, cv=5, scoring='r2')\n",
    "    print(f\"ğŸ“Š CV RÂ²: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"ğŸ“Œ Top Feature Importances:\")\n",
    "        fi = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(fi.head(5))\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print(\"ğŸ“Œ Top Coefficients:\")\n",
    "        coefs = pd.Series(model.coef_, index=X.columns).sort_values(key=np.abs, ascending=False)\n",
    "        print(coefs.head(5))\n",
    "    else:\n",
    "        print(\"âš ï¸ Feature importances not available.\")\n",
    "\n",
    "    path = f\"../data/preprocessed/glacier_regressor_{label}_{name}.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"ğŸ’¾ Model saved to: {path}\")\n",
    "\n",
    "# --- 7. Predict and save for Area Loss ---\n",
    "print(\"\\nğŸŒ Predicting Glacier Area Loss:\")\n",
    "for name, model in models.items():\n",
    "    evaluate_and_save_model(name, model, X_train, ya_train, X_test, ya_test, X, y_area, \"area\")\n",
    "\n",
    "# --- 8. Predict and save for Volume Loss ---\n",
    "print(\"\\nâ„ï¸ Predicting Glacier Volume Loss:\")\n",
    "for name, model in models.items():\n",
    "    evaluate_and_save_model(name, model, X_train, yv_train, X_test, yv_test, X, y_volume, \"volume\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d150059-9d75-497a-9446-aed52c43d12b",
   "metadata": {},
   "source": [
    "### âœ… Heatwave Days Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11006297-dff3-47ac-95b9-ccf6fe0f410b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Linear Regression Regression:\n",
      "ğŸ“ˆ RMSE: 7.13\n",
      "ğŸ“‰ MAE : 4.53\n",
      "ğŸ” RÂ²  : 0.8217\n",
      "ğŸ“Š CV RÂ²: 0.7362 Â± 0.1497\n",
      "ğŸ“Œ Top Coefficients:\n",
      "avg_wind                  8.978242\n",
      "temp_range_stddev         5.262960\n",
      "temp_range_stddev_lag1   -4.218279\n",
      "avg_temp_lag1            -2.901453\n",
      "avg_max_temp              2.859666\n",
      "precip_zscore_lag1        1.672863\n",
      "drought_risk_Severe       1.537184\n",
      "precip_zscore            -1.254348\n",
      "drought_risk_None         0.895688\n",
      "highheat_days_lag1        0.713396\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/heatwave_regressor_linear_regression.joblib\n",
      "\n",
      "ğŸ” Random Forest Regression:\n",
      "ğŸ“ˆ RMSE: 5.16\n",
      "ğŸ“‰ MAE : 2.30\n",
      "ğŸ” RÂ²  : 0.9068\n",
      "ğŸ“Š CV RÂ²: 0.8400 Â± 0.1365\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "avg_max_temp              0.778684\n",
      "highheat_days_lag1        0.072629\n",
      "temp_range_stddev         0.037122\n",
      "avg_temp                  0.032392\n",
      "avg_wind                  0.015560\n",
      "avg_humidity              0.014253\n",
      "avg_temp_lag1             0.009840\n",
      "temp_range_stddev_lag1    0.009381\n",
      "annual_precip_lag1        0.009368\n",
      "precip_zscore             0.007022\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/heatwave_regressor_random_forest.joblib\n",
      "\n",
      "ğŸ” Gradient Boosting Regression:\n",
      "ğŸ“ˆ RMSE: 5.15\n",
      "ğŸ“‰ MAE : 2.56\n",
      "ğŸ” RÂ²  : 0.9069\n",
      "ğŸ“Š CV RÂ²: 0.8424 Â± 0.1334\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "avg_max_temp              0.737821\n",
      "highheat_days_lag1        0.153114\n",
      "temp_range_stddev         0.041633\n",
      "avg_humidity              0.016393\n",
      "avg_temp                  0.009623\n",
      "temp_range_stddev_lag1    0.008770\n",
      "precip_zscore             0.006324\n",
      "annual_precip_lag1        0.006101\n",
      "annual_precip             0.005857\n",
      "avg_wind                  0.005606\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/heatwave_regressor_gradient_boosting.joblib\n",
      "\n",
      "ğŸ“‹ Regression Model Summary:\n",
      "               Model      RMSE       MAE  RÂ² Score  CV RÂ² Mean  CV RÂ² Std\n",
      "0  linear_regression  7.132995  4.534273  0.821674    0.736235   0.149722\n",
      "1      random_forest  5.155986  2.298387  0.906826    0.840044   0.136509\n",
      "2  gradient_boosting  5.152811  2.557829  0.906941    0.842440   0.133410\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# === Step 0: Ensure output directory exists ===\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "\n",
    "y = climate_yearly['highheat_days']\n",
    "\n",
    "# === Step 2: Define features ===\n",
    "X = climate_yearly.drop(columns=[\n",
    "    'District', 'YEAR', 'highheat_days', 'highheat_year'  # remove ID/leakage\n",
    "])\n",
    "\n",
    "# One-hot encode if any categorical columns exist\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Drop rows with missing data\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# === Step 3: Split data ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# === Step 4: Define models ===\n",
    "models = {\n",
    "    'linear_regression': LinearRegression(),\n",
    "    'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# === Step 5: Train and evaluate ===\n",
    "summary = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸ” {name.replace('_', ' ').title()} Regression:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"ğŸ“ˆ RMSE: {rmse:.2f}\")\n",
    "    print(f\"ğŸ“‰ MAE : {mae:.2f}\")\n",
    "    print(f\"ğŸ” RÂ²  : {r2:.4f}\")\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    print(f\"ğŸ“Š CV RÂ²: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "\n",
    "    # Feature insights\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"ğŸ“Œ Top Feature Importances:\")\n",
    "        fi = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(fi.head(10))\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print(\"ğŸ“Œ Top Coefficients:\")\n",
    "        coefs = pd.Series(model.coef_, index=X.columns).sort_values(key=np.abs, ascending=False)\n",
    "        print(coefs.head(10))\n",
    "    else:\n",
    "        print(\"âš ï¸ Feature importances not available.\")\n",
    "\n",
    "    # Save model\n",
    "    model_path = f\"../data/preprocessed/heatwave_regressor_{name}.joblib\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"ğŸ’¾ Model saved to: {model_path}\")\n",
    "\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'RÂ² Score': r2,\n",
    "        'CV RÂ² Mean': cv_scores.mean(),\n",
    "        'CV RÂ² Std': cv_scores.std()\n",
    "    })\n",
    "\n",
    "# === Step 6: Summary Table ===\n",
    "print(\"\\nğŸ“‹ Regression Model Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a04bb-04f3-40f5-96c9-4129f7cf8b4c",
   "metadata": {},
   "source": [
    "### âœ… Drought Severity Regression using precip_zscore (SPI proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ac79cc1-4ba9-44d0-80f9-f004d56b3dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” LINEAR_REGRESSION Regression:\n",
      "ğŸ“ˆ RMSE: 0.1966\n",
      "ğŸ“‰ MAE : 0.1339\n",
      "ğŸ” RÂ²  : 0.9624\n",
      "ğŸ“Š CV RÂ²: 0.9601 Â± 0.0123\n",
      "ğŸ“Œ Top Coefficients:\n",
      "precip_zscore_lag1        0.865977\n",
      "temp_range_stddev         0.090480\n",
      "temp_range_stddev_lag1   -0.014425\n",
      "avg_temp_lag1             0.009640\n",
      "avg_max_temp             -0.008935\n",
      "avg_wind                  0.007001\n",
      "avg_humidity              0.006215\n",
      "avg_temp                 -0.005258\n",
      "annual_precip             0.002875\n",
      "annual_precip_lag1       -0.002676\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/drought_regressor_linear_regression.joblib\n",
      "\n",
      "ğŸ” RANDOM_FOREST Regression:\n",
      "ğŸ“ˆ RMSE: 0.2321\n",
      "ğŸ“‰ MAE : 0.1436\n",
      "ğŸ” RÂ²  : 0.9476\n",
      "ğŸ“Š CV RÂ²: 0.9223 Â± 0.0634\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "annual_precip             0.645946\n",
      "precip_zscore_lag1        0.184665\n",
      "avg_humidity              0.069620\n",
      "annual_precip_lag1        0.021370\n",
      "avg_temp_lag1             0.017162\n",
      "avg_max_temp              0.014386\n",
      "avg_temp                  0.013539\n",
      "avg_wind                  0.012283\n",
      "temp_range_stddev         0.010312\n",
      "temp_range_stddev_lag1    0.008739\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/drought_regressor_random_forest.joblib\n",
      "\n",
      "ğŸ” GRADIENT_BOOSTING Regression:\n",
      "ğŸ“ˆ RMSE: 0.2429\n",
      "ğŸ“‰ MAE : 0.1759\n",
      "ğŸ” RÂ²  : 0.9426\n",
      "ğŸ“Š CV RÂ²: 0.9230 Â± 0.0498\n",
      "ğŸ“Œ Top Feature Importances:\n",
      "annual_precip             0.614139\n",
      "precip_zscore_lag1        0.232318\n",
      "avg_humidity              0.075419\n",
      "annual_precip_lag1        0.023750\n",
      "avg_max_temp              0.018793\n",
      "temp_range_stddev         0.009816\n",
      "avg_temp_lag1             0.009133\n",
      "avg_temp                  0.006992\n",
      "avg_wind                  0.005143\n",
      "temp_range_stddev_lag1    0.002752\n",
      "dtype: float64\n",
      "ğŸ’¾ Model saved to: ../data/preprocessed/drought_regressor_gradient_boosting.joblib\n",
      "\n",
      "ğŸ“‹ Regression Model Summary:\n",
      "               Model      RMSE       MAE  RÂ² Score  CV RÂ² Mean  CV RÂ² Std\n",
      "0  linear_regression  0.196566  0.133893  0.962372    0.960062   0.012263\n",
      "1      random_forest  0.232058  0.143619  0.947557    0.922349   0.063384\n",
      "2  gradient_boosting  0.242855  0.175870  0.942564    0.923037   0.049840\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# === Ensure output directory exists ===\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "# === 1. Define target and features ===\n",
    "y = climate_yearly['precip_zscore']  # SPI-like drought index\n",
    "\n",
    "X = climate_yearly.drop(columns=[\n",
    "    'precip_zscore', 'drought_risk', 'highheat_days', 'highheat_year',\n",
    "    'District', 'YEAR'\n",
    "])\n",
    "\n",
    "# Convert categoricals (if any)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Drop rows with missing values\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "\n",
    "# === 2. Train/test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# === 3. Define regression models ===\n",
    "models = {\n",
    "    'linear_regression': LinearRegression(),\n",
    "    'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'gradient_boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "# === 4. Evaluate and save each model ===\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nğŸ” {name.upper()} Regression:\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"ğŸ“ˆ RMSE: {rmse:.4f}\")\n",
    "    print(f\"ğŸ“‰ MAE : {mae:.4f}\")\n",
    "    print(f\"ğŸ” RÂ²  : {r2:.4f}\")\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    print(f\"ğŸ“Š CV RÂ²: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")\n",
    "\n",
    "    # Save summary\n",
    "    summary.append({\n",
    "        'Model': name,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'RÂ² Score': r2,\n",
    "        'CV RÂ² Mean': cv_scores.mean(),\n",
    "        'CV RÂ² Std': cv_scores.std()\n",
    "    })\n",
    "\n",
    "    # Feature importances / coefficients\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        print(\"ğŸ“Œ Top Feature Importances:\")\n",
    "        importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "        print(importances.head(10))\n",
    "    elif hasattr(model, 'coef_'):\n",
    "        print(\"ğŸ“Œ Top Coefficients:\")\n",
    "        coefs = pd.Series(model.coef_, index=X.columns).sort_values(key=np.abs, ascending=False)\n",
    "        print(coefs.head(10))\n",
    "    else:\n",
    "        print(\"âš ï¸ Feature importance not available.\")\n",
    "\n",
    "    # Save model\n",
    "    path = f\"../data/preprocessed/drought_regressor_{name}.joblib\"\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"ğŸ’¾ Model saved to: {path}\")\n",
    "\n",
    "# === 5. Print Summary Table ===\n",
    "print(\"\\nğŸ“‹ Regression Model Summary:\")\n",
    "print(pd.DataFrame(summary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384eaf6-44a4-451e-9c0f-dad3bdd1b3a2",
   "metadata": {},
   "source": [
    "### ğŸ”¹ Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661923fc-06b7-47b9-9687-ee7137672644",
   "metadata": {},
   "source": [
    "### âœ… Heatwarve Days Forecasting up to 2050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fb87656-33f3-4cee-b4bd-9a4b494c6e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Forecast Preview (2050):\n",
      "          District  YEAR  predicted_highheat_days\n",
      "30    Arghakhanchi  2050                     12.1\n",
      "61         Baglung  2050                     11.0\n",
      "92         Baitadi  2050                      1.8\n",
      "123         Bajang  2050                      0.5\n",
      "154          Banke  2050                      3.5\n",
      "...            ...   ...                      ...\n",
      "1797       Syangja  2050                      2.0\n",
      "1828       Tanahun  2050                      2.0\n",
      "1859     Taplejung  2050                      4.9\n",
      "1890     Terhathum  2050                      4.9\n",
      "1921      Udayapur  2050                      7.9\n",
      "\n",
      "[62 rows x 3 columns]\n",
      "ğŸ’¾ Forecast saved to: ../data/preprocessed/highheat_days_forecast_2020_2050.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import os\n",
    "\n",
    "#  input features \n",
    "features = [\n",
    "    'avg_temp', 'avg_max_temp', 'temp_range_stddev', 'avg_humidity',\n",
    "    'avg_wind', 'annual_precip', 'precip_zscore',\n",
    "    'avg_temp_lag1', 'annual_precip_lag1', 'precip_zscore_lag1',\n",
    "    'temp_range_stddev_lag1', 'highheat_days_lag1'\n",
    "]\n",
    "\n",
    "\n",
    "df = climate_yearly.copy()\n",
    "df_model = df[['District', 'YEAR', 'highheat_days'] + features].dropna()\n",
    "\n",
    "X = df_model[features]\n",
    "y = df_model['highheat_days']\n",
    "\n",
    "# === 3. Train model ===\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# === 4. Prepare forecast years and districts ===\n",
    "future_years = list(range(2020, 2051))\n",
    "districts = df_model['District'].unique()\n",
    "forecast_rows = []\n",
    "\n",
    "# === 5. Simulate future values per district ===\n",
    "for district in districts:\n",
    "    district_df = df_model[df_model['District'] == district]\n",
    "    if district_df.empty:\n",
    "        continue\n",
    "\n",
    "    last_row = district_df.loc[district_df['YEAR'].idxmax()].copy()\n",
    "\n",
    "    for year in future_years:\n",
    "        new_row = {'District': district, 'YEAR': year}\n",
    "\n",
    "        for col in features:\n",
    "            if 'lag1' in col:\n",
    "                base_col = col.replace('_lag1', '')\n",
    "                val = last_row.get(base_col, df_model[base_col].mean())\n",
    "                new_row[col] = val\n",
    "            else:\n",
    "                val = last_row.get(col, df_model[col].mean())\n",
    "                new_row[col] = val + np.random.normal(0, 0.1)  # small noise\n",
    "\n",
    "        forecast_rows.append(new_row)\n",
    "        last_row = pd.Series(new_row)\n",
    "\n",
    "# === 6. Predict and output ===\n",
    "forecast_df = pd.DataFrame(forecast_rows)\n",
    "forecast_df = forecast_df.dropna(subset=features)\n",
    "forecast_df['predicted_highheat_days'] = model.predict(forecast_df[features])\n",
    "\n",
    "# === 7. Save output ===\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "forecast_df.to_csv(\"../data/preprocessed/highheat_days_forecast_2020_2050.csv\", index=False)\n",
    "\n",
    "# === 8. Preview ===\n",
    "print(\"âœ… Forecast Preview (2050):\")\n",
    "print(forecast_df[forecast_df['YEAR'] == 2050][['District', 'YEAR', 'predicted_highheat_days']].round(1))\n",
    "print(\"ğŸ’¾ Forecast saved to: ../data/preprocessed/highheat_days_forecast_2020_2050.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a9c4b3-0fd5-4407-9f62-6989790acb66",
   "metadata": {},
   "source": [
    "### âœ… Forecasting Drought Severity to 2050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3f54740d-3f3b-41ec-b73f-093cc76ee424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Drought Forecast Preview (2050):\n",
      "          District  YEAR  predicted_spi drought_risk\n",
      "30    Arghakhanchi  2050           1.75         None\n",
      "61         Baglung  2050           1.96         None\n",
      "92         Baitadi  2050           1.13         None\n",
      "123         Bajang  2050           1.11         None\n",
      "154          Banke  2050           1.30         None\n",
      "...            ...   ...            ...          ...\n",
      "1797       Syangja  2050           1.92         None\n",
      "1828       Tanahun  2050           2.62         None\n",
      "1859     Taplejung  2050           1.53         None\n",
      "1890     Terhathum  2050           1.60         None\n",
      "1921      Udayapur  2050           1.30         None\n",
      "\n",
      "[62 rows x 4 columns]\n",
      "ğŸ’¾ Forecast saved to: ../data/preprocessed/drought_forecast_spi_2020_2050.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import os\n",
    "\n",
    "# Define features used for SPI prediction\n",
    "features = [\n",
    "    'annual_precip', 'avg_temp', 'avg_max_temp', 'avg_humidity',\n",
    "    'avg_wind', 'temp_range_stddev',\n",
    "    'annual_precip_lag1', 'avg_temp_lag1', 'temp_range_stddev_lag1'\n",
    "]\n",
    "target = 'precip_zscore'  # SPI proxy\n",
    "\n",
    "df = climate_yearly.copy()\n",
    "df_model = df[['District', 'YEAR', target] + features].dropna()\n",
    "\n",
    "# Train Gradient Boosting model on historical SPI data ---\n",
    "X = df_model[features]\n",
    "y = df_model[target]\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "#  Forecast SPI for each district from 2020 to 2050 ---\n",
    "future_years = list(range(2020, 2051))\n",
    "districts = df_model['District'].unique()\n",
    "forecast_rows = []\n",
    "\n",
    "for district in districts:\n",
    "    district_df = df_model[df_model['District'] == district].copy()\n",
    "    if district_df.empty:\n",
    "        continue\n",
    "\n",
    "    last_known = district_df[district_df['YEAR'] == district_df['YEAR'].max()]\n",
    "    if last_known.empty:\n",
    "        continue\n",
    "\n",
    "    last_row = last_known.iloc[0].copy()\n",
    "\n",
    "    for year in future_years:\n",
    "        new_row = {'District': district, 'YEAR': year}\n",
    "        for col in features:\n",
    "            if 'lag1' in col:\n",
    "                base_col = col.replace('_lag1', '')\n",
    "                val = last_row.get(base_col, df_model[base_col].mean())\n",
    "                new_row[col] = val\n",
    "            else:\n",
    "                base_val = last_row.get(col, df_model[col].mean())\n",
    "                new_row[col] = base_val + np.random.normal(0, 0.1)\n",
    "        forecast_rows.append(new_row)\n",
    "        last_row = pd.Series(new_row)\n",
    "\n",
    "# --- 5. Predict SPI and classify drought severity ---\n",
    "forecast_df = pd.DataFrame(forecast_rows)\n",
    "forecast_df = forecast_df.dropna(subset=features)\n",
    "forecast_df['predicted_spi'] = model.predict(forecast_df[features])\n",
    "\n",
    "def classify_spi(z):\n",
    "    if z >= -0.5:\n",
    "        return \"None\"\n",
    "    elif z >= -1.0:\n",
    "        return \"Mild\"\n",
    "    elif z >= -1.5:\n",
    "        return \"Moderate\"\n",
    "    elif z >= -2.0:\n",
    "        return \"Severe\"\n",
    "    else:\n",
    "        return \"Extreme\"\n",
    "\n",
    "forecast_df['drought_risk'] = forecast_df['predicted_spi'].apply(classify_spi)\n",
    "\n",
    "# --- 6. Save and preview forecast ---\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "forecast_path = \"../data/preprocessed/drought_forecast_spi_2020_2050.csv\"\n",
    "forecast_df.to_csv(forecast_path, index=False)\n",
    "\n",
    "print(\"âœ… Drought Forecast Preview (2050):\")\n",
    "print(forecast_df[forecast_df['YEAR'] == 2050][['District', 'YEAR', 'predicted_spi', 'drought_risk']].round(2))\n",
    "print(f\"ğŸ’¾ Forecast saved to: {forecast_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d2f2ea-05b8-499c-93aa-29bee7b5439b",
   "metadata": {},
   "source": [
    "### âœ… Climate Forecast Up to 2050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "12f0b3dc-289f-4910-a2e4-a358d8a18981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Climate Forecast Preview (2050):\n",
      "          District  YEAR  predicted_avg_temp\n",
      "30    Arghakhanchi  2050               22.62\n",
      "61         Baglung  2050               14.35\n",
      "92         Baitadi  2050                9.96\n",
      "123         Bajang  2050                3.26\n",
      "154          Banke  2050               21.61\n",
      "...            ...   ...                 ...\n",
      "1797       Syangja  2050               18.42\n",
      "1828       Tanahun  2050               12.77\n",
      "1859     Taplejung  2050               12.79\n",
      "1890     Terhathum  2050               13.85\n",
      "1921      Udayapur  2050               22.93\n",
      "\n",
      "[62 rows x 3 columns]\n",
      "ğŸ’¾ Forecast saved to: ../data/preprocessed/climate_forecast_2020_2050.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import joblib\n",
    "\n",
    "# Define features for forecasting ===\n",
    "features = [\n",
    "    'avg_temp', 'avg_max_temp', 'temp_range_stddev', 'avg_humidity',\n",
    "    'avg_wind', 'annual_precip',\n",
    "    'avg_temp_lag1', 'annual_precip_lag1', 'temp_range_stddev_lag1'\n",
    "]\n",
    "\n",
    "\n",
    "df = climate_yearly.copy()\n",
    "df_model = df[['District', 'YEAR'] + features].dropna()\n",
    "\n",
    "# Train Gradient Boosting model on historical avg_temp ===\n",
    "X = df_model[features]\n",
    "y = df_model['avg_temp']\n",
    "\n",
    "model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Save trained model\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "joblib.dump(model, \"../data/preprocessed/climate_regressor_avg_temp_gradient_boosting.joblib\")\n",
    "\n",
    "# Define forecast range ===\n",
    "future_years = list(range(2020, 2051))\n",
    "districts = df_model['District'].unique()\n",
    "forecast_rows = []\n",
    "\n",
    "#  Forward simulate features by district ===\n",
    "for district in districts:\n",
    "    district_df = df_model[df_model['District'] == district]\n",
    "    if district_df.empty:\n",
    "        continue\n",
    "\n",
    "    last_row = district_df.loc[district_df['YEAR'].idxmax()].copy()\n",
    "\n",
    "    for year in future_years:\n",
    "        new_row = {'District': district, 'YEAR': year}\n",
    "\n",
    "        for col in features:\n",
    "            if 'lag1' in col:\n",
    "                base_col = col.replace('_lag1', '')\n",
    "                val = last_row.get(base_col, df_model[base_col].mean())\n",
    "                new_row[col] = val\n",
    "            else:\n",
    "                val = last_row.get(col, df_model[col].mean())\n",
    "                new_row[col] = val + np.random.normal(0, 0.1)\n",
    "\n",
    "        forecast_rows.append(new_row)\n",
    "        last_row = pd.Series(new_row)\n",
    "\n",
    "# Predict future avg_temp ===\n",
    "forecast_df = pd.DataFrame(forecast_rows)\n",
    "forecast_df = forecast_df.dropna(subset=features)\n",
    "forecast_df['predicted_avg_temp'] = model.predict(forecast_df[features])\n",
    "\n",
    "# Save results ===\n",
    "forecast_path = \"../data/preprocessed/climate_forecast_2020_2050.csv\"\n",
    "forecast_df.to_csv(forecast_path, index=False)\n",
    "\n",
    "# Preview ===\n",
    "print(\"âœ… Climate Forecast Preview (2050):\")\n",
    "print(forecast_df[forecast_df['YEAR'] == 2050][['District', 'YEAR', 'predicted_avg_temp']].round(2))\n",
    "print(f\"ğŸ’¾ Forecast saved to: {forecast_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3f2dcd-5947-404d-ad5d-66b862285e02",
   "metadata": {},
   "source": [
    "### âœ… Glacier Area, Ice Volume, and Minimum Elevation Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89e121c3-9075-4344-877d-06569f6f4a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Glacier Forecast for 2050:\n",
      "    year     basin      sub-basin  predicted_glacier_area  \\\n",
      "57  2050  Mahakali       Mahakali                  110.15   \n",
      "58  2050   Karnali      West Seti                  151.56   \n",
      "59  2050   Karnali         Kawari                   20.03   \n",
      "60  2050   Karnali          Humla                  345.47   \n",
      "61  2050   Karnali           Mugu                  117.08   \n",
      "62  2050   Karnali           Tila                   23.69   \n",
      "63  2050   Karnali          Bheri                  364.77   \n",
      "64  2050   Gandaki   Kali Gandaki                  544.68   \n",
      "65  2050   Gandaki           Seti                   68.43   \n",
      "66  2050   Gandaki     Marsyangdi                  519.82   \n",
      "67  2050   Gandaki  Budhi Gandaki                  347.12   \n",
      "68  2050   Gandaki       Trishuli                  211.47   \n",
      "69  2050     Koshi      Indrawati                    5.39   \n",
      "70  2050     Koshi      Sun Koshi                   58.44   \n",
      "71  2050     Koshi     Tama Koshi                   87.01   \n",
      "72  2050     Koshi          Likhu                   14.93   \n",
      "73  2050     Koshi     Dudh Koshi                  398.47   \n",
      "74  2050     Koshi           Arun                  147.83   \n",
      "75  2050     Koshi          Tamor                  386.73   \n",
      "\n",
      "    predicted_ice_volume  predicted_min_elev  \n",
      "57                  6.98             3712.99  \n",
      "58                  7.62             4126.51  \n",
      "59                  1.17             3701.76  \n",
      "60                 19.25             4268.54  \n",
      "61                  5.94             4461.09  \n",
      "62                  1.20             4129.26  \n",
      "63                 25.09             4122.46  \n",
      "64                 39.26             3828.75  \n",
      "65                  6.93             3844.92  \n",
      "66                 40.98             3681.05  \n",
      "67                 29.21             3285.65  \n",
      "68                 18.96             3667.41  \n",
      "69                  1.26             4782.97  \n",
      "70                  4.29             4051.86  \n",
      "71                  8.24             4353.56  \n",
      "72                  1.17             4281.92  \n",
      "73                 39.30             4402.74  \n",
      "74                 15.14             4205.56  \n",
      "75                 42.54             4171.94  \n",
      "ğŸ’¾ Forecast saved to: ../data/preprocessed/glacier_forecast_2020_2050.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import os\n",
    "\n",
    "\n",
    "os.makedirs(\"../data/preprocessed\", exist_ok=True)\n",
    "\n",
    "df = glacier_long.copy()\n",
    "\n",
    "# Encode categorical variables ---\n",
    "df['basin_code'] = df['basin'].astype('category').cat.codes\n",
    "df['subbasin_code'] = df['sub-basin'].astype('category').cat.codes\n",
    "\n",
    "# Define input features and target variables ---\n",
    "features = ['year', 'basin_code', 'subbasin_code']\n",
    "targets = ['glacier_area', 'ice_volume', 'min_elev']\n",
    "\n",
    "# Train one model per target ---\n",
    "models = {}\n",
    "for target in targets:\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "    model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X, y)\n",
    "    models[target] = model\n",
    "\n",
    "# Generate forecast input combinations ---\n",
    "future_years = [2020, 2030, 2040, 2050]\n",
    "basin_info = df[['basin', 'sub-basin', 'basin_code', 'subbasin_code']].drop_duplicates()\n",
    "forecast_rows = []\n",
    "\n",
    "for year in future_years:\n",
    "    for _, row in basin_info.iterrows():\n",
    "        input_dict = {\n",
    "            'year': year,\n",
    "            'basin_code': row['basin_code'],\n",
    "            'subbasin_code': row['subbasin_code']\n",
    "        }\n",
    "        result = {\n",
    "            'year': year,\n",
    "            'basin': row['basin'],\n",
    "            'sub-basin': row['sub-basin']\n",
    "        }\n",
    "        for target in targets:\n",
    "            prediction = models[target].predict(pd.DataFrame([input_dict]))[0]\n",
    "            result[f'predicted_{target}'] = round(float(prediction), 4)\n",
    "        forecast_rows.append(result)\n",
    "\n",
    "# Create forecast DataFrame ---\n",
    "forecast_df = pd.DataFrame(forecast_rows)\n",
    "\n",
    "# Preview and save ---\n",
    "print(\"âœ… Glacier Forecast for 2050:\")\n",
    "print(forecast_df[forecast_df['year'] == 2050].round(2))\n",
    "\n",
    "forecast_path = \"../data/preprocessed/glacier_forecast_2020_2050.csv\"\n",
    "forecast_df.to_csv(forecast_path, index=False)\n",
    "print(f\"ğŸ’¾ Forecast saved to: {forecast_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f859299-9765-4447-92bd-025c9a5f7df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
